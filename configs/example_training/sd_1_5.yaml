model:
  base_learning_rate: 3.0e-5  
  target: sgm.models.diffusion.DiffusionEngine
  params:
    input_key: latents
    no_log_keys: [audio_emb, fps_id, motion_bucket_id, cond_aug, txt]
    scale_factor: 0.18215
    # scale_factor: 0.13025
    disable_first_stage_autocast: True
    separate_unet_ckpt: checkpoints/unet_1_5.pt
    ckpt_path: checkpoints/leosamsFilmgirlUltra_ultraBaseModel_renamed.safetensors
    # remove_keys_from_weights: [model.diffusion_model.input_blocks.0.0.weight]
    # remove_keys_from_unet_weights: [conv_in.weight]
    compile_model: False

    scheduler_config:
      target: sgm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [1000]
        cycle_lengths: [10000000000000]
        f_start: [1.e-6]
        f_max: [1.]
        f_min: [1.]

    only_train_ipadapter: True
    use_lora: false
    # to_unfreeze: ["conv_in", "down_blocks"]
    lora_config:
      search_class_str: Linear
      target_replace_module: null
      r_linear: 16
      r_conv: 16
      loras: null  # path to lora .pt
      exclude_layers: []
      verbose: False

    network_wrapper: 
      target: sgm.modules.diffusionmodules.wrappers.StabilityWrapper
      params:
        use_ipadapter: True
        ipadapter_model: ip-adapter_sd15.bin
        adapter_scale: 1.
        n_adapters: 2

    denoiser_config:
      target: sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser
      params:
        num_idx: 1000

        scaling_config:
          target: sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling
        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    network_config:
      target: sgm.modules.diffusionmodules.diffuser_unet.UNet2DConditionModel
      params:
        in_channels: 4
        act_fn: silu
        attention_head_dim: 8
        block_out_channels: [
          320,
          640,
          1280,
          1280
        ]
        center_input_sample: false
        cross_attention_dim: 768
        down_block_types: [
          CrossAttnDownBlock2D,
          CrossAttnDownBlock2D,
          CrossAttnDownBlock2D,
          DownBlock2D
        ]
        downsample_padding: 1
        flip_sin_to_cos: true
        freq_shift: 0
        layers_per_block: 2
        mid_block_scale_factor: 1
        norm_eps: 1e-05
        norm_num_groups: 32
        out_channels: 4
        sample_size: 64
        up_block_types: [
          UpBlock2D,
          CrossAttnUpBlock2D,
          CrossAttnUpBlock2D,
          CrossAttnUpBlock2D
        ]
        audio_cond_method: null
        audio_emb_dim: 1280

    conditioner_config:
      target: sgm.modules.GeneralConditioner
      params:
        emb_models:
          - is_trainable: False
            input_key: txt
            # ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenCLIPEmbedder
            params:
              layer: last
              null_text_path: /vol/paramonos2/projects/antoni/code/Personal/generative-models/checkpoints/null_txt.pt
              # layer_idx: 11
          # - is_trainable: False
          #   input_key: txt
          #   target: sgm.modules.encoders.modules.FrozenCLIPImagePredictionEmbedder
          #   params:
          #     n_cond_frames: 1
          #     n_copies: 1
          #     clip_embedding_config:
          #       target: sgm.modules.encoders.modules.FrozenCLIPImageEmbedder
          #       params:
          #         freeze: True
          #         version: openai/clip-vit-large-patch14
          #         subfolder: ""

          - is_trainable: False
            input_key: landmarks
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenCLIPImagePredictionEmbedder
            params:
              n_cond_frames: 1
              n_copies: 1
              give_cond_type: "landmarks"
              clip_embedding_config:
                target: sgm.modules.encoders.modules.FrozenCLIPImageEmbedder
                params:
                  freeze: True
                  get_hidden_states: False

          - is_trainable: False
            input_key: cond_frames_without_noise
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenCLIPImagePredictionEmbedder
            params:
              n_cond_frames: 1
              n_copies: 1
              give_cond_type: "image_embeds"
              clip_embedding_config:
                target: sgm.modules.encoders.modules.FrozenCLIPImageEmbedder
                params:
                  freeze: True
                  get_hidden_states: False

          # - input_key: cond_frames
          #   is_trainable: False
          #   ucg_rate: 0.1
          #   target: sgm.modules.encoders.modules.IdentityEncoder
            # params:
            #   disable_encoder_autocast: True
            #   n_cond_frames: 1
            #   n_copies: 1
            #   is_ae: True
            #   encoder_config:
            #     target: sgm.models.autoencoder.AutoencoderKLModeOnly
            #     params:
            #       embed_dim: 4
            #       monitor: val/rec_loss
            #       ddconfig:
            #         attn_type: vanilla-xformers
            #         double_z: True
            #         z_channels: 4
            #         resolution: 256
            #         in_channels: 3
            #         out_ch: 3
            #         ch: 128
            #         ch_mult: [1, 2, 4, 4]
            #         num_res_blocks: 2
            #         attn_resolutions: []
            #         dropout: 0.0
            #       lossconfig:
            #         target: torch.nn.Identity

          # - input_key: audio_emb
          #   is_trainable: True
          #   ucg_rate: 0.1
          #   target: sgm.modules.encoders.modules.WhisperAudioEmbedder
          #   params:
          #     merge_method: mean 
          #     linear_dim: 1024

    first_stage_config:
      target: sgm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    loss_fn_config:
          target: sgm.modules.diffusionmodules.loss.StandardDiffusionLoss
          params:        
            # # batch2model_keys:
            # #   - image_only_indicator
            # #   - num_video_frames
            # loss_weighting_config:
            #   target: sgm.modules.diffusionmodules.loss_weighting.EpsWeighting
            # sigma_sampler_config:
            #   target: sgm.modules.diffusionmodules.sigma_sampling.EDMSampling
            #   params:
            #     p_mean: 0.7
            #     p_std: 1.6
            loss_weighting_config:
              target: sgm.modules.diffusionmodules.loss_weighting.EpsWeighting
            sigma_sampler_config:
              target: sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling
              params:
                num_idx: 1000

                discretization_config:
                  target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    sampler_config:
          target: sgm.modules.diffusionmodules.sampling.EulerEDMSampler
          params:
            num_steps: 30
            # s_churn: 0.
            # s_tmin: 0.
            # s_tmax: 999.
            # s_noise: 1.
            discretization_config:
              target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization
              # params:
              #   sigma_max: 700.0

            guider_config:
              target: sgm.modules.diffusionmodules.guiders.VanillaCFG
              params:
                scale: 1.4

data:
  target: sgm.data.video_image_datamodule.VideoDataModule
  params:
    train:
      datapipeline:
        filelist: /home/abigata/PhD/datasets/HDTF/filelist_train.txt
        resize_size: 512
        audio_folder: audio
        video_folder: cropped_videos_original
        video_extension: .mp4
        audio_extension: .wav
        audio_rate: 16000
        num_frames: 14
        use_latent: True
        latent_type: video
        latent_scale: 1  # For backwards compatibility
        from_audio_embedding: True
        load_all_possible_indexes: False
        allow_all_possible_permutations: False
        audio_emb_type: whisper
        # cond_noise: [-3.0, 0.5]
        cond_noise: 0.
        motion_id: 60
        # data_mean: null
        # data_std: null
        additional_audio_frames: 2
        virtual_increase: 10000
        use_latent_condition: True
        get_landmarks: True

      loader:
        batch_size: 24
        num_workers: 8
        drop_last: True
        pin_memory: True
        persistent_workers: True

lightning:
  modelcheckpoint:
    params:
      every_n_train_steps: 5000
      save_top_k: 1

  callbacks:
    metrics_over_trainsteps_checkpoint:
      params:
        every_n_train_steps: 25000

    video_logger:
      target: sgm.callbacks.image_logger.ImageLogger
      params:
        disabled: False
        enable_autocast: False
        batch_frequency: 1000
        max_images: 4
        increase_log_steps: False
        log_first_step: True
        log_images_kwargs:
          ucg_keys: [cond_frames_without_noise, landmarks]
          use_ema_scope: False
          N: 4
          n_rows: 2

  trainer:
    devices: -1
    benchmark: False
    num_sanity_val_steps: 1
    accumulate_grad_batches: 1
    max_epochs: 1000
    precision: 16