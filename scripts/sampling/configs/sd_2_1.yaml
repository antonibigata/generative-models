model:
  base_learning_rate: 3.0e-5  
  target: sgm.models.diffusion.DiffusionEngine
  params:
    scale_factor: 0.18215
    # scale_factor: 0.13025
    disable_first_stage_autocast: True
    ckpt_path: /home/abigata/PhD/code/generative-models/checkpoints/last.ckpt
    # remove_keys_from_weights: [model.diffusion_model.input_blocks.0.0.weight]
    # compile_model: False

    # scheduler_config:
    #   target: sgm.lr_scheduler.LambdaLinearScheduler
    #   params:
    #     warm_up_steps: [10000]
    #     cycle_lengths: [10000000000000]
    #     f_start: [1.e-6]
    #     f_max: [1.]
    #     f_min: [1.]

    use_lora: false
    lora_config:
      search_class_str: Linear
      target_replace_module: null
      r_linear: 16
      r_conv: 16
      loras: null  # path to lora .pt
      exclude_layers: []
      verbose: False

    denoiser_config:
      target: sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser
      params:
        num_idx: 1000

        scaling_config:
          target: sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling
        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    network_config:
      target: sgm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        use_checkpoint: True
        in_channels: 8
        out_channels: 4
        model_channels: 320
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_head_channels: 64
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024
        fine_tuning_method: null
        unfreeze_input_blocks: True # Because we changed the input block
        spatial_transformer_attn_type: softmax-xformers
        audio_cond_method: cross_attention

    conditioner_config:
      target: sgm.modules.GeneralConditioner
      params:
        emb_models:
          # - is_trainable: False
          #   input_key: txt
          #   target: sgm.modules.encoders.modules.FrozenOpenCLIPEmbedder
          #   params:
          #     freeze: true
          #     layer: penultimate

          - is_trainable: False
            input_key: cond_frames_without_noise
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenOpenCLIPImagePredictionEmbedder
            params:
              n_cond_frames: 1
              n_copies: 1
              open_clip_embedding_config:
                target: sgm.modules.encoders.modules.FrozenOpenCLIPImageEmbedder
                params:
                  freeze: True

          - input_key: cond_frames
            is_trainable: False
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.VideoPredictionEmbedderWithEncoder
            params:
              disable_encoder_autocast: True
              n_cond_frames: 1
              n_copies: 1
              is_ae: True
              encoder_config:
                target: sgm.models.autoencoder.AutoencoderKLModeOnly
                params:
                  embed_dim: 4
                  monitor: val/rec_loss
                  ddconfig:
                    attn_type: vanilla-xformers
                    double_z: True
                    z_channels: 4
                    resolution: 256
                    in_channels: 3
                    out_ch: 3
                    ch: 128
                    ch_mult: [1, 2, 4, 4]
                    num_res_blocks: 2
                    attn_resolutions: []
                    dropout: 0.0
                  lossconfig:
                    target: torch.nn.Identity

          - input_key: audio_emb
            is_trainable: True
            target: sgm.modules.encoders.modules.WhisperAudioEmbedder
            params:
              merge_method: mean 
              linear_dim: 1024

    first_stage_config:
      target: sgm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    sampler_config:
          target: sgm.modules.diffusionmodules.sampling.EulerEDMSampler
          params:
            num_steps: 50
            # s_churn: 0.
            # s_tmin: 0.
            # s_tmax: 999.
            # s_noise: 1.
            discretization_config:
              target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization
              # params:
              #   sigma_max: 700.0

            guider_config:
              target: sgm.modules.diffusionmodules.guiders.VanillaCFG
              params:
                scale: 2.5

