{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "checkpoint = load_file(\"../checkpoints/svd_no_emb.safetensors\")\n",
    "\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([key for key in checkpoint.keys() if key.startswith(\"model.diffusion_model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from omegaconf import OmegaConf\n",
    "from sgm.util import instantiate_from_config\n",
    "\n",
    "config = OmegaConf.load(\"../configs/example_training/keyframes_base.yaml\")\n",
    "print(config)\n",
    "config[\"model\"][\"params\"][\"ckpt_path\"] = None\n",
    "video_model = instantiate_from_config(config.model)\n",
    "video_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from omegaconf import OmegaConf\n",
    "from sgm.util import instantiate_from_config\n",
    "\n",
    "config = OmegaConf.load(\"../configs/example_training/keyframes_base_bad.yaml\")\n",
    "print(config)\n",
    "config[\"model\"][\"params\"][\"ckpt_path\"] = None\n",
    "video_model_bad = instantiate_from_config(config.model)\n",
    "video_model_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_model_bad.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_state_dicts(model_state_dict, checkpoint_state_dict):\n",
    "    model_keys = set(k for k in model_state_dict.keys() if k.startswith(\"model.diffusion_model\"))\n",
    "    checkpoint_keys = set(k for k in checkpoint_state_dict.keys() if k.startswith(\"model.diffusion_model\"))\n",
    "\n",
    "    print(\"Keys in model but not in checkpoint:\")\n",
    "    for key in model_keys - checkpoint_keys:\n",
    "        print(key)\n",
    "\n",
    "    print(\"\\nKeys in checkpoint but not in model:\")\n",
    "    extra_keys = checkpoint_keys - model_keys\n",
    "    for key in extra_keys:\n",
    "        print(key)\n",
    "\n",
    "    return extra_keys\n",
    "\n",
    "\n",
    "def adjust_checkpoint(checkpoint, extra_keys):\n",
    "    modified_checkpoint = {}\n",
    "    for key, value in checkpoint.items():\n",
    "        if key in extra_keys:\n",
    "            continue  # Skip the extra keys\n",
    "        if \"input_blocks\" in key or \"output_blocks\" in key:\n",
    "            parts = key.split(\".\")\n",
    "            block_num = int(parts[3])\n",
    "            if block_num > 0:\n",
    "                new_block_num = block_num - 1\n",
    "                new_key = \".\".join(parts[:3] + [str(new_block_num)] + parts[4:])\n",
    "                modified_checkpoint[new_key] = value\n",
    "            else:\n",
    "                modified_checkpoint[key] = value\n",
    "        else:\n",
    "            modified_checkpoint[key] = value\n",
    "    return modified_checkpoint\n",
    "\n",
    "\n",
    "# Compare the state dicts and get the extra keys\n",
    "extra_keys = compare_state_dicts(video_model_bad.state_dict(), checkpoint)\n",
    "\n",
    "# Adjust the checkpoint\n",
    "adjusted_checkpoint = adjust_checkpoint(checkpoint, extra_keys)\n",
    "\n",
    "# Compare the adjusted checkpoint with the model\n",
    "compare_state_dicts(video_model_bad.state_dict(), adjusted_checkpoint)\n",
    "\n",
    "# Compare the state dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input block difference (used for output block adjustment): 3\n",
      "Original checkpoint keys: 2446\n",
      "Modified state dict keys: 2377\n"
     ]
    }
   ],
   "source": [
    "# Create a new dictionary for the modified weights\n",
    "modified_checkpoint = {}\n",
    "\n",
    "\n",
    "# Create a new state dict for the modified model\n",
    "modified_state_dict = {}\n",
    "# Iterate through the keys in the original checkpoint\n",
    "input_block_keys = set()\n",
    "output_block_keys = set()\n",
    "\n",
    "for key in checkpoint.keys():\n",
    "    if key.startswith(\"model.diffusion_model\"):\n",
    "        if \"input_blocks\" in key:\n",
    "            input_block_keys.add(key)\n",
    "        elif \"output_blocks\" in key:\n",
    "            output_block_keys.add(key)\n",
    "\n",
    "# Count input blocks in state_bad\n",
    "# Get max input block number in state_bad\n",
    "state_bad_max_input_block = max(\n",
    "    [\n",
    "        int(key.split(\".\")[3])\n",
    "        for key in video_model_bad.state_dict().keys()\n",
    "        if key.startswith(\"model.diffusion_model.input_blocks\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "checkpoint_max_input_block = max(\n",
    "    [int(key.split(\".\")[3]) for key in checkpoint.keys() if key.startswith(\"model.diffusion_model.input_blocks.\")]\n",
    ")\n",
    "\n",
    "# Calculate the difference in input blocks\n",
    "input_block_diff = checkpoint_max_input_block - state_bad_max_input_block\n",
    "\n",
    "\n",
    "# Function to adjust output block numbers\n",
    "def adjust_output_block_number(key, diff):\n",
    "    parts = key.split(\".\")\n",
    "    block_index = parts.index(\"output_blocks\") + 1\n",
    "    current_block = int(parts[block_index])\n",
    "    new_block = max(0, current_block - diff)\n",
    "    parts[block_index] = str(new_block)\n",
    "    return \".\".join(parts)\n",
    "\n",
    "\n",
    "# Adjust only output blocks\n",
    "for key, value in checkpoint.items():\n",
    "    if key.startswith(\"model.diffusion_model\"):\n",
    "        if \"output_blocks\" in key:\n",
    "            new_key = adjust_output_block_number(key, input_block_diff)\n",
    "            modified_state_dict[new_key] = value\n",
    "        else:\n",
    "            modified_state_dict[key] = value\n",
    "    else:\n",
    "        modified_state_dict[key] = value\n",
    "\n",
    "# Print some information for verification\n",
    "print(f\"Input block difference (used for output block adjustment): {input_block_diff}\")\n",
    "print(f\"Original checkpoint keys: {len(checkpoint)}\")\n",
    "print(f\"Modified state dict keys: {len(modified_state_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the modified state dict with safetensors\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "save_file(modified_state_dict, \"../checkpoints/svd_bad.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DiffusionEngine:\n\tMissing key(s) in state_dict: \"conditioner.embedders.3.linear.weight\", \"conditioner.embedders.3.linear.bias\". \n\tUnexpected key(s) in state_dict: \"model.diffusion_model.input_blocks.10.0.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.10.0.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.10.0.in_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.in_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.in_layers.2.bias\", \"model.diffusion_model.input_blocks.10.0.in_layers.2.weight\", \"model.diffusion_model.input_blocks.10.0.out_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.out_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.out_layers.3.bias\", \"model.diffusion_model.input_blocks.10.0.out_layers.3.weight\", \"model.diffusion_model.input_blocks.10.0.time_mixer.mix_factor\", \"model.diffusion_model.input_blocks.10.0.time_stack.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.2.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.2.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.3.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.3.weight\", \"model.diffusion_model.input_blocks.11.0.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.11.0.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.11.0.in_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.in_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.in_layers.2.bias\", \"model.diffusion_model.input_blocks.11.0.in_layers.2.weight\", \"model.diffusion_model.input_blocks.11.0.out_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.out_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.out_layers.3.bias\", \"model.diffusion_model.input_blocks.11.0.out_layers.3.weight\", \"model.diffusion_model.input_blocks.11.0.time_mixer.mix_factor\", \"model.diffusion_model.input_blocks.11.0.time_stack.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.2.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.2.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.3.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.3.weight\", \"model.diffusion_model.input_blocks.9.0.op.bias\", \"model.diffusion_model.input_blocks.9.0.op.weight\", \"model.diffusion_model.output_blocks.0.1.conv.bias\", \"model.diffusion_model.output_blocks.0.1.conv.weight\", \"conditioner.embedders.0.open_clip.model.ln_final.bias\", \"conditioner.embedders.0.open_clip.model.ln_final.weight\", \"conditioner.embedders.0.open_clip.model.logit_scale\", \"conditioner.embedders.0.open_clip.model.positional_embedding\", \"conditioner.embedders.0.open_clip.model.text_projection\", \"conditioner.embedders.0.open_clip.model.token_embedding.weight\", \"conditioner.embedders.0.open_clip.model.visual.class_embedding\", \"conditioner.embedders.0.open_clip.model.visual.conv1.weight\", \"conditioner.embedders.0.open_clip.model.visual.ln_post.bias\", \"conditioner.embedders.0.open_clip.model.visual.ln_post.weight\", \"conditioner.embedders.0.open_clip.model.visual.ln_pre.bias\", \"conditioner.embedders.0.open_clip.model.visual.ln_pre.weight\", \"conditioner.embedders.0.open_clip.model.visual.positional_embedding\", \"conditioner.embedders.0.open_clip.model.visual.proj\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_proj.weight\", \"conditioner.embedders.1.encoder.decoder.conv_in.bias\", \"conditioner.embedders.1.encoder.decoder.conv_in.weight\", \"conditioner.embedders.1.encoder.decoder.conv_out.bias\", \"conditioner.embedders.1.encoder.decoder.conv_out.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.k.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.k.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.norm.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.norm.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.proj_out.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.proj_out.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.q.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.q.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.v.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.v.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.norm_out.bias\", \"conditioner.embedders.1.encoder.decoder.norm_out.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.upsample.conv.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.upsample.conv.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.upsample.conv.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.upsample.conv.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.upsample.conv.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.upsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.conv_in.bias\", \"conditioner.embedders.1.encoder.encoder.conv_in.weight\", \"conditioner.embedders.1.encoder.encoder.conv_out.bias\", \"conditioner.embedders.1.encoder.encoder.conv_out.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.downsample.conv.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.downsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.downsample.conv.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.downsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.downsample.conv.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.downsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.k.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.k.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.norm.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.norm.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.proj_out.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.proj_out.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.q.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.q.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.v.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.v.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.norm_out.bias\", \"conditioner.embedders.1.encoder.encoder.norm_out.weight\", \"conditioner.embedders.1.encoder.post_quant_conv.bias\", \"conditioner.embedders.1.encoder.post_quant_conv.weight\", \"conditioner.embedders.1.encoder.quant_conv.bias\", \"conditioner.embedders.1.encoder.quant_conv.weight\". \n\tsize mismatch for model.diffusion_model.label_emb.0.0.weight: copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape in current model is torch.Size([1280, 1536]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvideo_model_bad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_state_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DiffusionEngine:\n\tMissing key(s) in state_dict: \"conditioner.embedders.3.linear.weight\", \"conditioner.embedders.3.linear.bias\". \n\tUnexpected key(s) in state_dict: \"model.diffusion_model.input_blocks.10.0.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.10.0.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.10.0.in_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.in_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.in_layers.2.bias\", \"model.diffusion_model.input_blocks.10.0.in_layers.2.weight\", \"model.diffusion_model.input_blocks.10.0.out_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.out_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.out_layers.3.bias\", \"model.diffusion_model.input_blocks.10.0.out_layers.3.weight\", \"model.diffusion_model.input_blocks.10.0.time_mixer.mix_factor\", \"model.diffusion_model.input_blocks.10.0.time_stack.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.2.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.in_layers.2.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.0.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.0.weight\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.3.bias\", \"model.diffusion_model.input_blocks.10.0.time_stack.out_layers.3.weight\", \"model.diffusion_model.input_blocks.11.0.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.11.0.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.11.0.in_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.in_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.in_layers.2.bias\", \"model.diffusion_model.input_blocks.11.0.in_layers.2.weight\", \"model.diffusion_model.input_blocks.11.0.out_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.out_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.out_layers.3.bias\", \"model.diffusion_model.input_blocks.11.0.out_layers.3.weight\", \"model.diffusion_model.input_blocks.11.0.time_mixer.mix_factor\", \"model.diffusion_model.input_blocks.11.0.time_stack.emb_layers.1.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.emb_layers.1.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.2.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.in_layers.2.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.0.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.0.weight\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.3.bias\", \"model.diffusion_model.input_blocks.11.0.time_stack.out_layers.3.weight\", \"model.diffusion_model.input_blocks.9.0.op.bias\", \"model.diffusion_model.input_blocks.9.0.op.weight\", \"model.diffusion_model.output_blocks.0.1.conv.bias\", \"model.diffusion_model.output_blocks.0.1.conv.weight\", \"conditioner.embedders.0.open_clip.model.ln_final.bias\", \"conditioner.embedders.0.open_clip.model.ln_final.weight\", \"conditioner.embedders.0.open_clip.model.logit_scale\", \"conditioner.embedders.0.open_clip.model.positional_embedding\", \"conditioner.embedders.0.open_clip.model.text_projection\", \"conditioner.embedders.0.open_clip.model.token_embedding.weight\", \"conditioner.embedders.0.open_clip.model.visual.class_embedding\", \"conditioner.embedders.0.open_clip.model.visual.conv1.weight\", \"conditioner.embedders.0.open_clip.model.visual.ln_post.bias\", \"conditioner.embedders.0.open_clip.model.visual.ln_post.weight\", \"conditioner.embedders.0.open_clip.model.visual.ln_pre.bias\", \"conditioner.embedders.0.open_clip.model.visual.ln_pre.weight\", \"conditioner.embedders.0.open_clip.model.visual.positional_embedding\", \"conditioner.embedders.0.open_clip.model.visual.proj\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.1.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.10.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.11.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.12.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.13.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.14.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.15.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.16.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.17.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.18.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.19.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.2.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.20.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.21.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.22.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.23.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.24.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.25.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.26.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.27.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.28.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.29.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.3.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.30.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.31.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.4.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.5.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.6.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.7.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.8.mlp.c_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.in_proj_bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.in_proj_weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.out_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.attn.out_proj.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_1.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_1.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_2.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.ln_2.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_fc.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_fc.weight\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_proj.bias\", \"conditioner.embedders.0.open_clip.model.visual.transformer.resblocks.9.mlp.c_proj.weight\", \"conditioner.embedders.1.encoder.decoder.conv_in.bias\", \"conditioner.embedders.1.encoder.decoder.conv_in.weight\", \"conditioner.embedders.1.encoder.decoder.conv_out.bias\", \"conditioner.embedders.1.encoder.decoder.conv_out.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.k.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.k.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.norm.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.norm.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.proj_out.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.proj_out.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.q.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.q.weight\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.v.bias\", \"conditioner.embedders.1.encoder.decoder.mid.attn_1.v.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.mid.block_2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.norm_out.bias\", \"conditioner.embedders.1.encoder.decoder.norm_out.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.0.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.1.upsample.conv.bias\", \"conditioner.embedders.1.encoder.decoder.up.1.upsample.conv.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.2.upsample.conv.bias\", \"conditioner.embedders.1.encoder.decoder.up.2.upsample.conv.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.conv2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm1.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm1.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm2.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.block.2.norm2.weight\", \"conditioner.embedders.1.encoder.decoder.up.3.upsample.conv.bias\", \"conditioner.embedders.1.encoder.decoder.up.3.upsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.conv_in.bias\", \"conditioner.embedders.1.encoder.encoder.conv_in.weight\", \"conditioner.embedders.1.encoder.encoder.conv_out.bias\", \"conditioner.embedders.1.encoder.encoder.conv_out.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.0.downsample.conv.bias\", \"conditioner.embedders.1.encoder.encoder.down.0.downsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.1.downsample.conv.bias\", \"conditioner.embedders.1.encoder.encoder.down.1.downsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.nin_shortcut.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.nin_shortcut.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.2.downsample.conv.bias\", \"conditioner.embedders.1.encoder.encoder.down.2.downsample.conv.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.0.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.down.3.block.1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.k.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.k.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.norm.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.norm.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.proj_out.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.proj_out.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.q.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.q.weight\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.v.bias\", \"conditioner.embedders.1.encoder.encoder.mid.attn_1.v.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_1.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.conv2.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm1.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm1.weight\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm2.bias\", \"conditioner.embedders.1.encoder.encoder.mid.block_2.norm2.weight\", \"conditioner.embedders.1.encoder.encoder.norm_out.bias\", \"conditioner.embedders.1.encoder.encoder.norm_out.weight\", \"conditioner.embedders.1.encoder.post_quant_conv.bias\", \"conditioner.embedders.1.encoder.post_quant_conv.weight\", \"conditioner.embedders.1.encoder.quant_conv.bias\", \"conditioner.embedders.1.encoder.quant_conv.weight\". \n\tsize mismatch for model.diffusion_model.label_emb.0.0.weight: copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape in current model is torch.Size([1280, 1536])."
     ]
    }
   ],
   "source": [
    "video_model_bad.load_state_dict(modified_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_bad = video_model_bad.state_dict()\n",
    "sorted([key for key in state_bad.keys() if key.startswith(\"model.diffusion_model\")])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
