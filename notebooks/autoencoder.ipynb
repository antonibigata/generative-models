{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/paramonos2/projects/antoni/miniconda3/envs/svd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'base_learning_rate': 3e-05, 'target': 'sgm.models.diffusion.DiffusionEngine', 'params': {'input_key': 'latents', 'no_log_keys': ['audio_emb', 'fps_id', 'motion_bucket_id', 'cond_aug'], 'scale_factor': 0.18215, 'disable_first_stage_autocast': True, 'ckpt_path': 'checkpoints/svd.safetensors', 'remove_keys_from_weights': ['model.diffusion_model.input_blocks.0.0.weight'], 'compile_model': False, 'scheduler_config': {'target': 'sgm.lr_scheduler.LambdaLinearScheduler', 'params': {'warm_up_steps': [1000], 'cycle_lengths': [10000000000000], 'f_start': [1e-06], 'f_max': [1.0], 'f_min': [1.0]}}, 'use_lora': False, 'lora_config': {'search_class_str': 'Linear', 'target_replace_module': None, 'r_linear': 16, 'r_conv': 16, 'loras': None}, 'denoiser_config': {'target': 'sgm.modules.diffusionmodules.denoiser.Denoiser', 'params': {'scaling_config': {'target': 'sgm.modules.diffusionmodules.denoiser_scaling.VScalingWithEDMcNoise'}}}, 'network_wrapper': {'target': 'sgm.modules.diffusionmodules.wrappers.InterpolationWrapper', 'params': {'im_size': [512, 512], 'n_channels': 4, 'starting_mask_method': 'zeros', 'add_mask': True}}, 'network_config': {'target': 'sgm.modules.diffusionmodules.video_model.VideoUNet', 'params': {'adm_in_channels': 768, 'num_classes': 'sequential', 'use_checkpoint': True, 'in_channels': 9, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'spatial_transformer_attn_type': 'softmax-xformers', 'extra_ff_mix_layer': True, 'use_spatial_context': True, 'merge_strategy': 'learned_with_images', 'video_kernel_size': [3, 1, 1], 'fine_tuning_method': None, 'audio_cond_method': 'cross_attention', 'unfreeze_blocks': ['input']}}, 'conditioner_config': {'target': 'sgm.modules.GeneralConditioner', 'params': {'emb_models': [{'is_trainable': False, 'input_key': 'cond_frames_without_noise', 'target': 'sgm.modules.encoders.modules.FrozenOpenCLIPImagePredictionEmbedder', 'params': {'n_cond_frames': 2, 'n_copies': 1, 'open_clip_embedding_config': {'target': 'sgm.modules.encoders.modules.FrozenOpenCLIPImageEmbedder', 'params': {'freeze': True}}}}, {'input_key': 'fps_id', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.ConcatTimestepEmbedderND', 'params': {'outdim': 256}}, {'input_key': 'motion_bucket_id', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.ConcatTimestepEmbedderND', 'params': {'outdim': 256}}, {'input_key': 'cond_frames', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.VideoPredictionEmbedderWithEncoder', 'params': {'disable_encoder_autocast': True, 'n_cond_frames': 2, 'n_copies': 1, 'is_ae': True, 'encoder_config': {'target': 'sgm.models.autoencoder.AutoencoderKLModeOnly', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'attn_type': 'vanilla-xformers', 'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}}}, {'input_key': 'cond_aug', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.ConcatTimestepEmbedderND', 'params': {'outdim': 256}}, {'input_key': 'audio_emb', 'is_trainable': True, 'ucg_rate': 0.1, 'target': 'sgm.modules.encoders.modules.WhisperAudioEmbedder', 'params': {'merge_method': 'none', 'linear_dim': 1024}}]}}, 'first_stage_config': {'target': 'sgm.models.autoencoder.AutoencodingEngine', 'params': {'loss_config': {'target': 'torch.nn.Identity'}, 'regularizer_config': {'target': 'sgm.modules.autoencoding.regularizers.DiagonalGaussianRegularizer'}, 'encoder_config': {'target': 'sgm.modules.diffusionmodules.model.Encoder', 'params': {'attn_type': 'vanilla', 'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}}, 'decoder_config': {'target': 'sgm.modules.autoencoding.temporal_ae.VideoDecoder', 'params': {'attn_type': 'vanilla', 'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}}}}, 'sampler_config': {'target': 'sgm.modules.diffusionmodules.sampling.EulerEDMSampler', 'params': {'num_steps': 25, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.EDMDiscretization', 'params': {'sigma_max': 700.0}}, 'guider_config': {'target': 'sgm.modules.diffusionmodules.guiders.TrianglePredictionGuider', 'params': {'max_scale': 2.5, 'min_scale': 1.0, 'num_frames': 14, 'period': [1, 1], 'period_fusing': 'multiply'}}}}, 'loss_fn_config': {'target': 'sgm.modules.diffusionmodules.loss.StandardDiffusionLoss', 'params': {'batch2model_keys': ['image_only_indicator', 'num_video_frames'], 'loss_weighting_config': {'target': 'sgm.modules.diffusionmodules.loss_weighting.EpsWeighting'}, 'sigma_sampler_config': {'target': 'sgm.modules.diffusionmodules.sigma_sampling.EDMSampling', 'params': {'p_mean': 1.0, 'p_std': 1.2}}}}}}, 'data': {'target': 'sgm.data.video_datamodule_latent.VideoDataModule', 'params': {'train': {'datapipeline': {'filelist': '/fsx/rs2517/data/lists/HDTF/filelist_videos_train.txt', 'resize_size': 512, 'audio_folder': 'audio', 'video_folder': 'cropped_videos_original', 'video_extension': '.mp4', 'audio_extension': '.wav', 'latent_folder': None, 'audio_in_video': False, 'audio_rate': 16000, 'num_frames': 14, 'need_cond': True, 'mode': 'interpolation', 'use_latent': True, 'latent_type': 'video', 'latent_scale': 1, 'from_audio_embedding': True, 'load_all_possible_indexes': True, 'audio_emb_type': 'whisper', 'cond_noise': [-3.0, 0.5], 'motion_id': 125, 'data_mean': None, 'data_std': None}, 'loader': {'batch_size': 1, 'num_workers': 6, 'drop_last': True, 'pin_memory': True, 'persistent_workers': True}}}}, 'lightning': {'modelcheckpoint': {'params': {'every_n_train_steps': 5000, 'save_top_k': 1}}, 'callbacks': {'metrics_over_trainsteps_checkpoint': {'params': {'every_n_train_steps': 25000}}, 'video_logger': {'target': 'sgm.callbacks.video_logger.VideoLogger', 'params': {'disabled': False, 'enable_autocast': False, 'batch_frequency': 1000, 'max_videos': 1, 'increase_log_steps': False, 'log_first_step': True, 'log_videos_kwargs': {'use_ema_scope': False, 'ucg_keys': ['audio_emb'], 'N': 1, 'n_rows': 1}}}}, 'trainer': {'devices': 4, 'benchmark': False, 'num_sanity_val_steps': 1, 'accumulate_grad_batches': 1, 'max_epochs': 1000, 'precision': 'bf16-mixed', 'num_nodes': 1}}}\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False\n",
      "Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #3: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False\n",
      "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #5: WhisperAudioEmbedder with 1311744 params. Trainable: True\n",
      "Restoring from ../checkpoints/svd.safetensors\n",
      "Loaded state dict from ../checkpoints/svd.safetensors with 2446 keys\n",
      "Restored from ../checkpoints/svd.safetensors with 436 missing and 0 unexpected keys\n",
      "Missing Keys: ['model.learned_mask', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.audio_stack.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.audio_mixer.mix_factor', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.audio_stack.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.audio_mixer.mix_factor', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.audio_stack.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.audio_mixer.mix_factor', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.audio_stack.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.audio_mixer.mix_factor', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.audio_stack.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.audio_mixer.mix_factor', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.audio_stack.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.audio_mixer.mix_factor', 'model.diffusion_model.middle_block.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.norm2.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.norm2.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.norm1.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.norm1.bias', 'model.diffusion_model.middle_block.1.audio_stack.0.norm3.weight', 'model.diffusion_model.middle_block.1.audio_stack.0.norm3.bias', 'model.diffusion_model.middle_block.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.audio_mixer.mix_factor', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm_in.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm_in.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff_in.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff_in.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff_in.net.2.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff_in.net.2.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.audio_stack.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.audio_mixer.mix_factor', 'conditioner.embedders.5.linear.weight', 'conditioner.embedders.5.linear.bias']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from omegaconf import OmegaConf\n",
    "from sgm.util import instantiate_from_config\n",
    "\n",
    "config = OmegaConf.load(\n",
    "    \"/vol/paramonos2/projects/antoni/code/Personal/generative-models/configs/example_training/svd_interpolation.yaml\"\n",
    ")\n",
    "print(config)\n",
    "config[\"model\"][\"params\"][\"ckpt_path\"] = \"../checkpoints/svd.safetensors\"\n",
    "video_model = instantiate_from_config(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.learned_mask.sum((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/vol/paramonos2/projects/antoni/miniconda3/envs/svd/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_video\n",
    "import torch\n",
    "\n",
    "video_path = \"/data2/Datasets/HDTF/cropped_videos_original/WRA_BobbySchilling_001.mp4\"\n",
    "resolution = 512\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "video, audio, info = read_video(video_path, pts_unit=\"sec\", output_format=\"TCHW\")\n",
    "\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "resize = Resize((resolution, resolution))\n",
    "video = resize(video)\n",
    "print(video.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/data2/Datasets/HDTF/audio/WRA_BobbySchilling_001_whisper_emb.pt\"\n",
    "audio = torch.load(audio_path)\n",
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = video_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.first_stage_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "encoded = model.conditioner.embedders[3]((video[:12].to(device).float() / 255.0) * 2 - 1) * 0.18215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgm.modules.lipreader.preparation.detectors.retinaface.video_process import VideoProcess\n",
    "import numpy as np\n",
    "\n",
    "video_process = VideoProcess(\n",
    "    convert_gray=False, crop_width=96 // 8, crop_height=96 // 8, reference_size=(64, 64), target_size=(64, 64)\n",
    ")\n",
    "landmarks = np.load(\"/data2/Datasets/HDTF/cropped_videos_original/RD_Radio18_000.npy\")\n",
    "from sgm.data.data_utils import scale_landmarks\n",
    "\n",
    "landmarks = scale_landmarks(landmarks, (772, 772), (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 8, 64, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "encoded_reshape = rearrange(encoded, \"b (t c) h w -> (b t) h w c\", c=4)\n",
    "\n",
    "video_proccessed = video_process(encoded_reshape.cpu().numpy(), landmarks[:12], True, threshold=30)\n",
    "video_proccessed = torch.tensor(video_proccessed)\n",
    "video_proccessed = rearrange(video_proccessed, \"b h w c -> b c h w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=80x80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "video_model.to(device)\n",
    "# decoded = video_model.decode_first_stage(encoded[:, 4:])\n",
    "# encoded = video_proccessed.cuda()\n",
    "decoded = video_model.decode_first_stage(encoded[:, 4:, 40:50, 30:40])\n",
    "img = Image.fromarray(np.uint8((decoded[0].clip(-1, 1).cpu().numpy().transpose(1, 2, 0) + 1) * 255 / 2))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "latent_path = \"/vol/bitbucket/abigata/00190_video_512_latent.safetensors\"\n",
    "\n",
    "latent = load_file(latent_path)\n",
    "latent[\"latents\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = video_model.decode_first_stage(latent[\"latents\"][:1].to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.fromarray(np.uint8((decoded[0].clip(-1, 1).cpu().numpy().transpose(1, 2, 0) + 1) * 255 / 2))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from omegaconf import OmegaConf\n",
    "from sgm.util import instantiate_from_config\n",
    "\n",
    "config = OmegaConf.load(\n",
    "    \"/vol/paramonos2/projects/antoni/code/Personal/generative-models/configs/inference/sd_2_1.yaml\"\n",
    ")\n",
    "print(config)\n",
    "config[\"model\"][\"params\"][\n",
    "    \"ckpt_path\"\n",
    "] = \"/vol/paramonos2/projects/antoni/code/Personal/generative-models/checkpoints/v2-1_512-ema-pruned.safetensors\"\n",
    "model = instantiate_from_config(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_video\n",
    "import torch\n",
    "\n",
    "video_path = \"/data2/Datasets/HDTF/cropped_videos_original/WRA_BobbySchilling_001.mp4\"\n",
    "resolution = 512\n",
    "device = torch.device(\"cuda:4\")\n",
    "\n",
    "video, audio, info = read_video(video_path, pts_unit=\"sec\", output_format=\"TCHW\")\n",
    "\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "resize = Resize((resolution, resolution))\n",
    "video = resize(video)\n",
    "print(video.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "encoded = model.encode_first_stage((video[:2].to(device).float() / 255.0) * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded = model.decode_first_stage(encoded)\n",
    "decoded = model.decode_first_stage(latent[\"latents\"][:1].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.fromarray(np.uint8((decoded[0].clip(-1, 1).cpu().numpy().transpose(1, 2, 0) + 1) * 255 / 2))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "# load model and tokenizer\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\", cache_dir=\"/vol/bitbucket/abigata/.cache\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\", cache_dir=\"/vol/bitbucket/abigata/.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "audio_path = \"/data2/Datasets/HDTF/audio/WRA_JeffFlake_001.wav\"\n",
    "audio, sr = torchaudio.load(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "audio_reshaped = rearrange(audio.mean(0)[:640000], \"(f s) -> f s\", s=320)\n",
    "audio_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = processor(audio=audio_reshaped, sampling_rate=sr, return_tensors=\"pt\", padding=\"longest\").input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "normed_slice = (audio - audio.mean()) / torch.sqrt(audio.var() + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outs = model(normed_slice[:, : 16000 * 3], output_hidden_states=True)\n",
    "    # hidden_states = model.wav2vec2(normed_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "rearanged = rearrange(hidden_states[0], \"() (f d) c -> f d c\", d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearanged[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.hidden_states[-1][:, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_video\n",
    "\n",
    "video_path = \"/data2/Datasets/HDTF/cropped_videos_original/WRA_JeffFlake_001.mp4\"\n",
    "resolution = 512\n",
    "device = torch.device(\"cuda:4\")\n",
    "\n",
    "video, audio, info = read_video(video_path, pts_unit=\"sec\", output_format=\"TCHW\")\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.logits.shape, 7500 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = torch.argmax(outs.logits, dim=-1).squeeze()\n",
    "\n",
    "# transcribe\n",
    "transcription = processor.decode(predicted_ids)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"NTRIES HAVE NEVER HAD FOR A SINGLE DAY IN THEIR LIVES BUT THE STORY OF THE PAST THREE AND A HALF YEARS IS A STORY OF THE POWER THAT WE VEST IN THE PRESIDENCY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "# load model and tokenizer\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\", cache_dir=\"/vol/bitbucket/abigata/.cache\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\", cache_dir=\"/vol/bitbucket/abigata/.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "audio_emb = torch.load(\"/data2/Datasets/VoxCeleb2/video/dev/mp4/id07085/NcpRWNyzlAA/00031_wav2vec2_emb.pt\")\n",
    "audio_emb = rearrange(audio_emb, \"f d c -> (f d) c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.lm_head(audio_emb).unsqueeze(0)\n",
    "predicted_ids = torch.argmax(logits, dim=-1).squeeze()\n",
    "\n",
    "# transcribe\n",
    "transcription = processor.decode(predicted_ids)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot video\n",
    "import moviepy.editor as mp\n",
    "\n",
    "mp.VideoFileClip(\"/vol/paramonos/datasets/VoxCeleb2/video/dev/mp4/id07085/NcpRWNyzlAA/00031.mp4\").ipython_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
