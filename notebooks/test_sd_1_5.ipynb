{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/paramonos2/projects/antoni/miniconda3/envs/svd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'target': 'sgm.models.diffusion.DiffusionEngine', 'params': {'scale_factor': 0.18215, 'disable_first_stage_autocast': True, 'denoiser_config': {'target': 'sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser', 'params': {'num_idx': 1000, 'scaling_config': {'target': 'sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling'}, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization'}}}, 'network_config': {'target': 'sgm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'use_checkpoint': True, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_linear_in_transformer': False, 'transformer_depth': 1, 'context_dim': 768}}, 'conditioner_config': {'target': 'sgm.modules.GeneralConditioner', 'params': {'emb_models': [{'is_trainable': False, 'input_key': 'txt', 'target': 'sgm.modules.encoders.modules.FrozenCLIPEmbedder', 'params': {'layer': 'last'}}]}}, 'first_stage_config': {'target': 'sgm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}}}}\n",
      "Initialized embedder #0: FrozenCLIPEmbedder with 123060480 params. Trainable: False\n",
      "Restored from /vol/paramonos2/projects/antoni/code/Personal/generative-models/checkpoints/leosamsFilmgirlUltra_ultraBaseModel.safetensors with 197 missing and 198 unexpected keys\n",
      "Missing Keys: ['denoiser.sigmas', 'conditioner.embedders.0.transformer.text_model.embeddings.token_embedding.weight', 'conditioner.embedders.0.transformer.text_model.embeddings.position_embedding.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'conditioner.embedders.0.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'conditioner.embedders.0.transformer.text_model.final_layer_norm.weight', 'conditioner.embedders.0.transformer.text_model.final_layer_norm.bias']\n",
      "Unexpected Keys: ['cond_stage_model.logit_scale', 'cond_stage_model.text_projection', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from omegaconf import OmegaConf\n",
    "from sgm.util import instantiate_from_config\n",
    "\n",
    "config = OmegaConf.load(\n",
    "    \"/vol/paramonos2/projects/antoni/code/Personal/generative-models/configs/inference/sd_1_5.yaml\"\n",
    ")\n",
    "print(config)\n",
    "config[\"model\"][\"params\"][\n",
    "    \"ckpt_path\"\n",
    "] = \"/vol/paramonos2/projects/antoni/code/Personal/generative-models/checkpoints/leosamsFilmgirlUltra_ultraBaseModel.safetensors\"\n",
    "# config[\"model\"][\"params\"][\"network_config\"][\"params\"][\"fine_tuning_method\"] = None\n",
    "model = instantiate_from_config(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/paramonos2/projects/antoni/miniconda3/envs/svd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 10.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n",
       "         [-0.1189,  1.0663,  2.0914,  ...,  0.3393, -0.4146,  0.6376],\n",
       "         [ 0.2818,  0.9080,  1.7518,  ...,  1.0331, -0.2975, -0.3620],\n",
       "         ...,\n",
       "         [ 0.9049, -0.0348,  0.5000,  ...,  2.3313, -0.7853, -0.6802],\n",
       "         [ 0.8800, -0.0329,  0.5009,  ...,  2.3420, -0.8227, -0.6749],\n",
       "         [ 0.9519,  0.0401,  0.5483,  ...,  2.2692, -0.7291, -0.6433]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipeline_1_5 = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    # torch_dtype=torch.float16,\n",
    "    cache_dir=\"/vol/paramonos2/projects/antoni/.cache\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "prompt_embeds, negative_prompt_embeds = pipeline_1_5.encode_prompt(\n",
    "    \"Chybre\",\n",
    "    \"cuda\",\n",
    "    1,\n",
    "    False,\n",
    ")\n",
    "prompt_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3883,  0.0229, -0.0520,  ..., -0.4898, -0.3066,  0.0674],\n",
       "         [-0.1190,  1.0676,  2.0905,  ...,  0.3391, -0.4161,  0.6374],\n",
       "         [ 0.2763,  0.9094,  1.7510,  ...,  1.0331, -0.2992, -0.3645],\n",
       "         ...,\n",
       "         [ 0.9047, -0.0336,  0.4978,  ...,  2.3328, -0.7846, -0.6800],\n",
       "         [ 0.8800, -0.0305,  0.4989,  ...,  2.3419, -0.8218, -0.6741],\n",
       "         [ 0.9512,  0.0413,  0.5462,  ...,  2.2694, -0.7275, -0.6435]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "emb = model.conditioner.embedders[0](\"Chybre\")\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(emb - prompt_embeds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.28.0.dev0\",\n",
       "  \"_name_or_path\": \"runwayml/stable-diffusion-v1-5\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"requires_safety_checker\": true,\n",
       "  \"safety_checker\": [\n",
       "    \"stable_diffusion\",\n",
       "    \"StableDiffusionSafetyChecker\"\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.diffusion_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
