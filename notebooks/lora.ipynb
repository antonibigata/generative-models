{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'base_learning_rate': 3e-05, 'target': 'sgm.models.diffusion.DiffusionEngine', 'params': {'input_key': 'latents', 'no_log_keys': ['audio_emb', 'fps_id', 'motion_bucket_id', 'cond_aug'], 'scale_factor': 0.18215, 'disable_first_stage_autocast': True, 'ckpt_path': 'checkpoints/svd.safetensors', 'denoiser_config': {'target': 'sgm.modules.diffusionmodules.denoiser.Denoiser', 'params': {'scaling_config': {'target': 'sgm.modules.diffusionmodules.denoiser_scaling.VScalingWithEDMcNoise'}}}, 'network_config': {'target': 'sgm.modules.diffusionmodules.video_model.VideoUNet', 'params': {'adm_in_channels': 768, 'num_classes': 'sequential', 'use_checkpoint': True, 'in_channels': 8, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'spatial_transformer_attn_type': 'softmax-xformers', 'extra_ff_mix_layer': True, 'use_spatial_context': True, 'merge_strategy': 'learned_with_images', 'video_kernel_size': [3, 1, 1], 'fine_tuning_method': 'lora', 'adapter_kwargs': {'target_replace_module': ['SpatialVideoTransformer'], 'r': 16, 'loras': None, 'verbose': False, 'dropout_p': 0.0, 'scale': 1.0}}}, 'conditioner_config': {'target': 'sgm.modules.GeneralConditioner', 'params': {'emb_models': [{'is_trainable': False, 'input_key': 'cond_frames_without_noise', 'target': 'sgm.modules.encoders.modules.FrozenOpenCLIPImagePredictionEmbedder', 'params': {'n_cond_frames': 1, 'n_copies': 1, 'open_clip_embedding_config': {'target': 'sgm.modules.encoders.modules.FrozenOpenCLIPImageEmbedder', 'params': {'freeze': True}}}}, {'input_key': 'fps_id', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.ConcatTimestepEmbedderND', 'params': {'outdim': 256}}, {'input_key': 'motion_bucket_id', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.ConcatTimestepEmbedderND', 'params': {'outdim': 256}}, {'input_key': 'cond_frames', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.VideoPredictionEmbedderWithEncoder', 'params': {'disable_encoder_autocast': True, 'n_cond_frames': 1, 'n_copies': 1, 'is_ae': True, 'encoder_config': {'target': 'sgm.models.autoencoder.AutoencoderKLModeOnly', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'attn_type': 'vanilla-xformers', 'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}}}, {'input_key': 'cond_aug', 'is_trainable': False, 'target': 'sgm.modules.encoders.modules.ConcatTimestepEmbedderND', 'params': {'outdim': 256}}, {'input_key': 'audio_emb', 'is_trainable': True, 'target': 'sgm.modules.encoders.modules.WhisperAudioEmbedder', 'params': {'merge_method': 'mean', 'linear_dim': None}}]}}, 'first_stage_config': {'target': 'sgm.models.autoencoder.AutoencodingEngine', 'params': {'loss_config': {'target': 'torch.nn.Identity'}, 'regularizer_config': {'target': 'sgm.modules.autoencoding.regularizers.DiagonalGaussianRegularizer'}, 'encoder_config': {'target': 'sgm.modules.diffusionmodules.model.Encoder', 'params': {'attn_type': 'vanilla', 'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}}, 'decoder_config': {'target': 'sgm.modules.autoencoding.temporal_ae.VideoDecoder', 'params': {'attn_type': 'vanilla', 'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}}}}, 'sampler_config': {'target': 'sgm.modules.diffusionmodules.sampling.EulerEDMSampler', 'params': {'num_steps': 25, 'discretization_config': {'target': 'sgm.modules.diffusionmodules.discretizer.EDMDiscretization', 'params': {'sigma_max': 700.0}}, 'guider_config': {'target': 'sgm.modules.diffusionmodules.guiders.LinearPredictionGuider', 'params': {'max_scale': 2.5, 'min_scale': 1.0, 'num_frames': 14}}}}, 'loss_fn_config': {'target': 'sgm.modules.diffusionmodules.loss.StandardDiffusionLoss', 'params': {'batch2model_keys': ['image_only_indicator', 'num_video_frames'], 'loss_weighting_config': {'target': 'sgm.modules.diffusionmodules.loss_weighting.EpsWeighting'}, 'sigma_sampler_config': {'target': 'sgm.modules.diffusionmodules.sigma_sampling.EDMSampling', 'params': {'p_mean': 0.7, 'p_std': 1.6}}}}}}, 'data': {'target': 'sgm.data.video_datamodule_latent.VideoDataModule', 'params': {'train': {'datapipeline': {'filelist': '/vol/paramonos2/projects/antoni/datasets/HDTF/filelist_videos_train.txt', 'resize_size': 512, 'audio_folder': 'audio', 'video_folder': 'cropped_videos_original', 'video_extension': '.mp4', 'audio_extension': '.wav', 'audio_rate': 16000, 'num_frames': 14, 'need_cond': False, 'mode': 'prediction', 'use_latent': True, 'latent_type': 'video', 'latent_scale': 1, 'from_audio_embedding': True, 'load_all_possible_indexes': True, 'audio_emb_type': 'whisper', 'cond_noise': [-3.0, 0.5], 'motion_id': 255.0, 'data_mean': None, 'data_std': None}, 'loader': {'batch_size': 1, 'num_workers': 6, 'drop_last': True, 'pin_memory': True, 'persistent_workers': True}}}}, 'lightning': {'modelcheckpoint': {'params': {'every_n_train_steps': 5000, 'save_top_k': 1}}, 'callbacks': {'metrics_over_trainsteps_checkpoint': {'params': {'every_n_train_steps': 25000}}, 'video_logger': {'target': 'sgm.callbacks.video_logger.VideoLogger', 'params': {'disabled': False, 'enable_autocast': False, 'batch_frequency': 1000, 'max_videos': 2, 'increase_log_steps': False, 'log_first_step': True, 'log_videos_kwargs': {'use_ema_scope': False, 'N': 2, 'n_rows': 1}}}}, 'trainer': {'devices': '4,', 'benchmark': False, 'num_sanity_val_steps': 1, 'accumulate_grad_batches': 1, 'max_epochs': 1000}}}\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "VideoTransformerBlock is using checkpointing\n",
      "Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False\n",
      "Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #3: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False\n",
      "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #5: WhisperAudioEmbedder with 0 params. Trainable: True\n",
      "Restored from /vol/paramonos2/projects/antoni/code/Personal/generative-models/checkpoints/svd.safetensors with 0 missing and 0 unexpected keys\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from omegaconf import OmegaConf\n",
    "from sgm.util import instantiate_from_config\n",
    "\n",
    "config = OmegaConf.load(\n",
    "    \"/vol/paramonos2/projects/antoni/code/Personal/generative-models/configs/example_training/svd_training.yaml\"\n",
    ")\n",
    "print(config)\n",
    "config[\"model\"][\"params\"][\n",
    "    \"ckpt_path\"\n",
    "] = \"/vol/paramonos2/projects/antoni/code/Personal/generative-models/checkpoints/svd.safetensors\"\n",
    "config[\"model\"][\"params\"][\"network_config\"][\"params\"][\"fine_tuning_method\"] = None\n",
    "model = instantiate_from_config(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "model_ckpt = load_file(\"../checkpoints/svd.safetensors\")\n",
    "\n",
    "print(model_ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = model.model.diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgm.modules.diffusionmodules.adapters.lora import apply_lora\n",
    "import torch\n",
    "\n",
    "# activate_lora = add_lora_to(unet, [\"SpatialVideoTransformer\"], search_class=[torch.nn.Linear], r=32, dropout=0, lora_bias=\"none\")\n",
    "apply_lora(unet, filters=[\".input_blocks\"], rank=16, all_modules_in_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgm.modules.diffusionmodules.adapters.lora import LoRA\n",
    "\n",
    "lora = {}\n",
    "lora[\"weights\"] = torch.nn.ModuleList()\n",
    "for module in unet.modules():\n",
    "    if isinstance(module, LoRA) or (\n",
    "        hasattr(module, \"_fsdp_wrapped_module\") and isinstance(module._fsdp_wrapped_module, LoRA)\n",
    "    ):\n",
    "        print(module.requires_grad_())\n",
    "        lora[\"weights\"].append(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in unet.parameters():\n",
    "    if param.requires_grad:\n",
    "        print(\"requires grad\")\n",
    "    else:\n",
    "        print(\"does not require grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in unet.input_blocks[0].parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time_embed\n",
      "time_embed.0\n",
      "time_embed.1\n",
      "time_embed.2\n",
      "label_emb\n",
      "label_emb.0\n",
      "label_emb.0.0\n",
      "label_emb.0.1\n",
      "label_emb.0.2\n",
      "input_blocks\n",
      "input_blocks.0\n",
      "input_blocks.0.0\n",
      "input_blocks.1\n",
      "input_blocks.1.0\n",
      "input_blocks.1.0.in_layers\n",
      "input_blocks.1.0.in_layers.0\n",
      "input_blocks.1.0.in_layers.1\n",
      "input_blocks.1.0.in_layers.2\n",
      "input_blocks.1.0.h_upd\n",
      "input_blocks.1.0.emb_layers\n",
      "input_blocks.1.0.emb_layers.0\n",
      "input_blocks.1.0.emb_layers.1\n",
      "input_blocks.1.0.out_layers\n",
      "input_blocks.1.0.out_layers.0\n",
      "input_blocks.1.0.out_layers.1\n",
      "input_blocks.1.0.out_layers.2\n",
      "input_blocks.1.0.out_layers.3\n",
      "input_blocks.1.0.skip_connection\n",
      "input_blocks.1.0.time_stack\n",
      "input_blocks.1.0.time_stack.in_layers\n",
      "input_blocks.1.0.time_stack.in_layers.0\n",
      "input_blocks.1.0.time_stack.in_layers.1\n",
      "input_blocks.1.0.time_stack.in_layers.2\n",
      "input_blocks.1.0.time_stack.h_upd\n",
      "input_blocks.1.0.time_stack.emb_layers\n",
      "input_blocks.1.0.time_stack.emb_layers.0\n",
      "input_blocks.1.0.time_stack.emb_layers.1\n",
      "input_blocks.1.0.time_stack.out_layers\n",
      "input_blocks.1.0.time_stack.out_layers.0\n",
      "input_blocks.1.0.time_stack.out_layers.1\n",
      "input_blocks.1.0.time_stack.out_layers.2\n",
      "input_blocks.1.0.time_stack.out_layers.3\n",
      "input_blocks.1.0.time_stack.skip_connection\n",
      "input_blocks.1.0.time_mixer\n",
      "input_blocks.1.1\n",
      "input_blocks.1.1.norm\n",
      "input_blocks.1.1.proj_in\n",
      "input_blocks.1.1.transformer_blocks\n",
      "input_blocks.1.1.transformer_blocks.0\n",
      "input_blocks.1.1.transformer_blocks.0.attn1\n",
      "input_blocks.1.1.transformer_blocks.0.attn1.to_q\n",
      "input_blocks.1.1.transformer_blocks.0.attn1.to_k\n",
      "input_blocks.1.1.transformer_blocks.0.attn1.to_v\n",
      "input_blocks.1.1.transformer_blocks.0.attn1.to_out\n",
      "input_blocks.1.1.transformer_blocks.0.attn1.to_out.0\n",
      "input_blocks.1.1.transformer_blocks.0.attn1.to_out.1\n",
      "input_blocks.1.1.transformer_blocks.0.ff\n",
      "input_blocks.1.1.transformer_blocks.0.ff.net\n",
      "input_blocks.1.1.transformer_blocks.0.ff.net.0\n",
      "input_blocks.1.1.transformer_blocks.0.ff.net.0.proj\n",
      "input_blocks.1.1.transformer_blocks.0.ff.net.1\n",
      "input_blocks.1.1.transformer_blocks.0.ff.net.2\n",
      "input_blocks.1.1.transformer_blocks.0.attn2\n",
      "input_blocks.1.1.transformer_blocks.0.attn2.to_q\n",
      "input_blocks.1.1.transformer_blocks.0.attn2.to_k\n",
      "input_blocks.1.1.transformer_blocks.0.attn2.to_v\n",
      "input_blocks.1.1.transformer_blocks.0.attn2.to_out\n",
      "input_blocks.1.1.transformer_blocks.0.attn2.to_out.0\n",
      "input_blocks.1.1.transformer_blocks.0.attn2.to_out.1\n",
      "input_blocks.1.1.transformer_blocks.0.norm1\n",
      "input_blocks.1.1.transformer_blocks.0.norm2\n",
      "input_blocks.1.1.transformer_blocks.0.norm3\n",
      "input_blocks.1.1.proj_out\n",
      "input_blocks.1.1.time_stack\n",
      "input_blocks.1.1.time_stack.0\n",
      "input_blocks.1.1.time_stack.0.norm_in\n",
      "input_blocks.1.1.time_stack.0.ff_in\n",
      "input_blocks.1.1.time_stack.0.ff_in.net\n",
      "input_blocks.1.1.time_stack.0.ff_in.net.0\n",
      "input_blocks.1.1.time_stack.0.ff_in.net.0.proj\n",
      "input_blocks.1.1.time_stack.0.ff_in.net.1\n",
      "input_blocks.1.1.time_stack.0.ff_in.net.2\n",
      "input_blocks.1.1.time_stack.0.attn1\n",
      "input_blocks.1.1.time_stack.0.attn1.to_q\n",
      "input_blocks.1.1.time_stack.0.attn1.to_k\n",
      "input_blocks.1.1.time_stack.0.attn1.to_v\n",
      "input_blocks.1.1.time_stack.0.attn1.to_out\n",
      "input_blocks.1.1.time_stack.0.attn1.to_out.0\n",
      "input_blocks.1.1.time_stack.0.attn1.to_out.1\n",
      "input_blocks.1.1.time_stack.0.ff\n",
      "input_blocks.1.1.time_stack.0.ff.net\n",
      "input_blocks.1.1.time_stack.0.ff.net.0\n",
      "input_blocks.1.1.time_stack.0.ff.net.0.proj\n",
      "input_blocks.1.1.time_stack.0.ff.net.1\n",
      "input_blocks.1.1.time_stack.0.ff.net.2\n",
      "input_blocks.1.1.time_stack.0.norm2\n",
      "input_blocks.1.1.time_stack.0.attn2\n",
      "input_blocks.1.1.time_stack.0.attn2.to_q\n",
      "input_blocks.1.1.time_stack.0.attn2.to_k\n",
      "input_blocks.1.1.time_stack.0.attn2.to_v\n",
      "input_blocks.1.1.time_stack.0.attn2.to_out\n",
      "input_blocks.1.1.time_stack.0.attn2.to_out.0\n",
      "input_blocks.1.1.time_stack.0.attn2.to_out.1\n",
      "input_blocks.1.1.time_stack.0.norm1\n",
      "input_blocks.1.1.time_stack.0.norm3\n",
      "input_blocks.1.1.time_pos_embed\n",
      "input_blocks.1.1.time_pos_embed.0\n",
      "input_blocks.1.1.time_pos_embed.1\n",
      "input_blocks.1.1.time_pos_embed.2\n",
      "input_blocks.1.1.time_mixer\n",
      "input_blocks.2\n",
      "input_blocks.2.0\n",
      "input_blocks.2.0.in_layers\n",
      "input_blocks.2.0.in_layers.0\n",
      "input_blocks.2.0.in_layers.1\n",
      "input_blocks.2.0.in_layers.2\n",
      "input_blocks.2.0.h_upd\n",
      "input_blocks.2.0.emb_layers\n",
      "input_blocks.2.0.emb_layers.0\n",
      "input_blocks.2.0.emb_layers.1\n",
      "input_blocks.2.0.out_layers\n",
      "input_blocks.2.0.out_layers.0\n",
      "input_blocks.2.0.out_layers.1\n",
      "input_blocks.2.0.out_layers.2\n",
      "input_blocks.2.0.out_layers.3\n",
      "input_blocks.2.0.skip_connection\n",
      "input_blocks.2.0.time_stack\n",
      "input_blocks.2.0.time_stack.in_layers\n",
      "input_blocks.2.0.time_stack.in_layers.0\n",
      "input_blocks.2.0.time_stack.in_layers.1\n",
      "input_blocks.2.0.time_stack.in_layers.2\n",
      "input_blocks.2.0.time_stack.h_upd\n",
      "input_blocks.2.0.time_stack.emb_layers\n",
      "input_blocks.2.0.time_stack.emb_layers.0\n",
      "input_blocks.2.0.time_stack.emb_layers.1\n",
      "input_blocks.2.0.time_stack.out_layers\n",
      "input_blocks.2.0.time_stack.out_layers.0\n",
      "input_blocks.2.0.time_stack.out_layers.1\n",
      "input_blocks.2.0.time_stack.out_layers.2\n",
      "input_blocks.2.0.time_stack.out_layers.3\n",
      "input_blocks.2.0.time_stack.skip_connection\n",
      "input_blocks.2.0.time_mixer\n",
      "input_blocks.2.1\n",
      "input_blocks.2.1.norm\n",
      "input_blocks.2.1.proj_in\n",
      "input_blocks.2.1.transformer_blocks\n",
      "input_blocks.2.1.transformer_blocks.0\n",
      "input_blocks.2.1.transformer_blocks.0.attn1\n",
      "input_blocks.2.1.transformer_blocks.0.attn1.to_q\n",
      "input_blocks.2.1.transformer_blocks.0.attn1.to_k\n",
      "input_blocks.2.1.transformer_blocks.0.attn1.to_v\n",
      "input_blocks.2.1.transformer_blocks.0.attn1.to_out\n",
      "input_blocks.2.1.transformer_blocks.0.attn1.to_out.0\n",
      "input_blocks.2.1.transformer_blocks.0.attn1.to_out.1\n",
      "input_blocks.2.1.transformer_blocks.0.ff\n",
      "input_blocks.2.1.transformer_blocks.0.ff.net\n",
      "input_blocks.2.1.transformer_blocks.0.ff.net.0\n",
      "input_blocks.2.1.transformer_blocks.0.ff.net.0.proj\n",
      "input_blocks.2.1.transformer_blocks.0.ff.net.1\n",
      "input_blocks.2.1.transformer_blocks.0.ff.net.2\n",
      "input_blocks.2.1.transformer_blocks.0.attn2\n",
      "input_blocks.2.1.transformer_blocks.0.attn2.to_q\n",
      "input_blocks.2.1.transformer_blocks.0.attn2.to_k\n",
      "input_blocks.2.1.transformer_blocks.0.attn2.to_v\n",
      "input_blocks.2.1.transformer_blocks.0.attn2.to_out\n",
      "input_blocks.2.1.transformer_blocks.0.attn2.to_out.0\n",
      "input_blocks.2.1.transformer_blocks.0.attn2.to_out.1\n",
      "input_blocks.2.1.transformer_blocks.0.norm1\n",
      "input_blocks.2.1.transformer_blocks.0.norm2\n",
      "input_blocks.2.1.transformer_blocks.0.norm3\n",
      "input_blocks.2.1.proj_out\n",
      "input_blocks.2.1.time_stack\n",
      "input_blocks.2.1.time_stack.0\n",
      "input_blocks.2.1.time_stack.0.norm_in\n",
      "input_blocks.2.1.time_stack.0.ff_in\n",
      "input_blocks.2.1.time_stack.0.ff_in.net\n",
      "input_blocks.2.1.time_stack.0.ff_in.net.0\n",
      "input_blocks.2.1.time_stack.0.ff_in.net.0.proj\n",
      "input_blocks.2.1.time_stack.0.ff_in.net.1\n",
      "input_blocks.2.1.time_stack.0.ff_in.net.2\n",
      "input_blocks.2.1.time_stack.0.attn1\n",
      "input_blocks.2.1.time_stack.0.attn1.to_q\n",
      "input_blocks.2.1.time_stack.0.attn1.to_k\n",
      "input_blocks.2.1.time_stack.0.attn1.to_v\n",
      "input_blocks.2.1.time_stack.0.attn1.to_out\n",
      "input_blocks.2.1.time_stack.0.attn1.to_out.0\n",
      "input_blocks.2.1.time_stack.0.attn1.to_out.1\n",
      "input_blocks.2.1.time_stack.0.ff\n",
      "input_blocks.2.1.time_stack.0.ff.net\n",
      "input_blocks.2.1.time_stack.0.ff.net.0\n",
      "input_blocks.2.1.time_stack.0.ff.net.0.proj\n",
      "input_blocks.2.1.time_stack.0.ff.net.1\n",
      "input_blocks.2.1.time_stack.0.ff.net.2\n",
      "input_blocks.2.1.time_stack.0.norm2\n",
      "input_blocks.2.1.time_stack.0.attn2\n",
      "input_blocks.2.1.time_stack.0.attn2.to_q\n",
      "input_blocks.2.1.time_stack.0.attn2.to_k\n",
      "input_blocks.2.1.time_stack.0.attn2.to_v\n",
      "input_blocks.2.1.time_stack.0.attn2.to_out\n",
      "input_blocks.2.1.time_stack.0.attn2.to_out.0\n",
      "input_blocks.2.1.time_stack.0.attn2.to_out.1\n",
      "input_blocks.2.1.time_stack.0.norm1\n",
      "input_blocks.2.1.time_stack.0.norm3\n",
      "input_blocks.2.1.time_pos_embed\n",
      "input_blocks.2.1.time_pos_embed.0\n",
      "input_blocks.2.1.time_pos_embed.1\n",
      "input_blocks.2.1.time_pos_embed.2\n",
      "input_blocks.2.1.time_mixer\n",
      "input_blocks.3\n",
      "input_blocks.3.0\n",
      "input_blocks.3.0.op\n",
      "input_blocks.4\n",
      "input_blocks.4.0\n",
      "input_blocks.4.0.in_layers\n",
      "input_blocks.4.0.in_layers.0\n",
      "input_blocks.4.0.in_layers.1\n",
      "input_blocks.4.0.in_layers.2\n",
      "input_blocks.4.0.h_upd\n",
      "input_blocks.4.0.emb_layers\n",
      "input_blocks.4.0.emb_layers.0\n",
      "input_blocks.4.0.emb_layers.1\n",
      "input_blocks.4.0.out_layers\n",
      "input_blocks.4.0.out_layers.0\n",
      "input_blocks.4.0.out_layers.1\n",
      "input_blocks.4.0.out_layers.2\n",
      "input_blocks.4.0.out_layers.3\n",
      "input_blocks.4.0.skip_connection\n",
      "input_blocks.4.0.time_stack\n",
      "input_blocks.4.0.time_stack.in_layers\n",
      "input_blocks.4.0.time_stack.in_layers.0\n",
      "input_blocks.4.0.time_stack.in_layers.1\n",
      "input_blocks.4.0.time_stack.in_layers.2\n",
      "input_blocks.4.0.time_stack.h_upd\n",
      "input_blocks.4.0.time_stack.emb_layers\n",
      "input_blocks.4.0.time_stack.emb_layers.0\n",
      "input_blocks.4.0.time_stack.emb_layers.1\n",
      "input_blocks.4.0.time_stack.out_layers\n",
      "input_blocks.4.0.time_stack.out_layers.0\n",
      "input_blocks.4.0.time_stack.out_layers.1\n",
      "input_blocks.4.0.time_stack.out_layers.2\n",
      "input_blocks.4.0.time_stack.out_layers.3\n",
      "input_blocks.4.0.time_stack.skip_connection\n",
      "input_blocks.4.0.time_mixer\n",
      "input_blocks.4.1\n",
      "input_blocks.4.1.norm\n",
      "input_blocks.4.1.proj_in\n",
      "input_blocks.4.1.transformer_blocks\n",
      "input_blocks.4.1.transformer_blocks.0\n",
      "input_blocks.4.1.transformer_blocks.0.attn1\n",
      "input_blocks.4.1.transformer_blocks.0.attn1.to_q\n",
      "input_blocks.4.1.transformer_blocks.0.attn1.to_k\n",
      "input_blocks.4.1.transformer_blocks.0.attn1.to_v\n",
      "input_blocks.4.1.transformer_blocks.0.attn1.to_out\n",
      "input_blocks.4.1.transformer_blocks.0.attn1.to_out.0\n",
      "input_blocks.4.1.transformer_blocks.0.attn1.to_out.1\n",
      "input_blocks.4.1.transformer_blocks.0.ff\n",
      "input_blocks.4.1.transformer_blocks.0.ff.net\n",
      "input_blocks.4.1.transformer_blocks.0.ff.net.0\n",
      "input_blocks.4.1.transformer_blocks.0.ff.net.0.proj\n",
      "input_blocks.4.1.transformer_blocks.0.ff.net.1\n",
      "input_blocks.4.1.transformer_blocks.0.ff.net.2\n",
      "input_blocks.4.1.transformer_blocks.0.attn2\n",
      "input_blocks.4.1.transformer_blocks.0.attn2.to_q\n",
      "input_blocks.4.1.transformer_blocks.0.attn2.to_k\n",
      "input_blocks.4.1.transformer_blocks.0.attn2.to_v\n",
      "input_blocks.4.1.transformer_blocks.0.attn2.to_out\n",
      "input_blocks.4.1.transformer_blocks.0.attn2.to_out.0\n",
      "input_blocks.4.1.transformer_blocks.0.attn2.to_out.1\n",
      "input_blocks.4.1.transformer_blocks.0.norm1\n",
      "input_blocks.4.1.transformer_blocks.0.norm2\n",
      "input_blocks.4.1.transformer_blocks.0.norm3\n",
      "input_blocks.4.1.proj_out\n",
      "input_blocks.4.1.time_stack\n",
      "input_blocks.4.1.time_stack.0\n",
      "input_blocks.4.1.time_stack.0.norm_in\n",
      "input_blocks.4.1.time_stack.0.ff_in\n",
      "input_blocks.4.1.time_stack.0.ff_in.net\n",
      "input_blocks.4.1.time_stack.0.ff_in.net.0\n",
      "input_blocks.4.1.time_stack.0.ff_in.net.0.proj\n",
      "input_blocks.4.1.time_stack.0.ff_in.net.1\n",
      "input_blocks.4.1.time_stack.0.ff_in.net.2\n",
      "input_blocks.4.1.time_stack.0.attn1\n",
      "input_blocks.4.1.time_stack.0.attn1.to_q\n",
      "input_blocks.4.1.time_stack.0.attn1.to_k\n",
      "input_blocks.4.1.time_stack.0.attn1.to_v\n",
      "input_blocks.4.1.time_stack.0.attn1.to_out\n",
      "input_blocks.4.1.time_stack.0.attn1.to_out.0\n",
      "input_blocks.4.1.time_stack.0.attn1.to_out.1\n",
      "input_blocks.4.1.time_stack.0.ff\n",
      "input_blocks.4.1.time_stack.0.ff.net\n",
      "input_blocks.4.1.time_stack.0.ff.net.0\n",
      "input_blocks.4.1.time_stack.0.ff.net.0.proj\n",
      "input_blocks.4.1.time_stack.0.ff.net.1\n",
      "input_blocks.4.1.time_stack.0.ff.net.2\n",
      "input_blocks.4.1.time_stack.0.norm2\n",
      "input_blocks.4.1.time_stack.0.attn2\n",
      "input_blocks.4.1.time_stack.0.attn2.to_q\n",
      "input_blocks.4.1.time_stack.0.attn2.to_k\n",
      "input_blocks.4.1.time_stack.0.attn2.to_v\n",
      "input_blocks.4.1.time_stack.0.attn2.to_out\n",
      "input_blocks.4.1.time_stack.0.attn2.to_out.0\n",
      "input_blocks.4.1.time_stack.0.attn2.to_out.1\n",
      "input_blocks.4.1.time_stack.0.norm1\n",
      "input_blocks.4.1.time_stack.0.norm3\n",
      "input_blocks.4.1.time_pos_embed\n",
      "input_blocks.4.1.time_pos_embed.0\n",
      "input_blocks.4.1.time_pos_embed.1\n",
      "input_blocks.4.1.time_pos_embed.2\n",
      "input_blocks.4.1.time_mixer\n",
      "input_blocks.5\n",
      "input_blocks.5.0\n",
      "input_blocks.5.0.in_layers\n",
      "input_blocks.5.0.in_layers.0\n",
      "input_blocks.5.0.in_layers.1\n",
      "input_blocks.5.0.in_layers.2\n",
      "input_blocks.5.0.h_upd\n",
      "input_blocks.5.0.emb_layers\n",
      "input_blocks.5.0.emb_layers.0\n",
      "input_blocks.5.0.emb_layers.1\n",
      "input_blocks.5.0.out_layers\n",
      "input_blocks.5.0.out_layers.0\n",
      "input_blocks.5.0.out_layers.1\n",
      "input_blocks.5.0.out_layers.2\n",
      "input_blocks.5.0.out_layers.3\n",
      "input_blocks.5.0.skip_connection\n",
      "input_blocks.5.0.time_stack\n",
      "input_blocks.5.0.time_stack.in_layers\n",
      "input_blocks.5.0.time_stack.in_layers.0\n",
      "input_blocks.5.0.time_stack.in_layers.1\n",
      "input_blocks.5.0.time_stack.in_layers.2\n",
      "input_blocks.5.0.time_stack.h_upd\n",
      "input_blocks.5.0.time_stack.emb_layers\n",
      "input_blocks.5.0.time_stack.emb_layers.0\n",
      "input_blocks.5.0.time_stack.emb_layers.1\n",
      "input_blocks.5.0.time_stack.out_layers\n",
      "input_blocks.5.0.time_stack.out_layers.0\n",
      "input_blocks.5.0.time_stack.out_layers.1\n",
      "input_blocks.5.0.time_stack.out_layers.2\n",
      "input_blocks.5.0.time_stack.out_layers.3\n",
      "input_blocks.5.0.time_stack.skip_connection\n",
      "input_blocks.5.0.time_mixer\n",
      "input_blocks.5.1\n",
      "input_blocks.5.1.norm\n",
      "input_blocks.5.1.proj_in\n",
      "input_blocks.5.1.transformer_blocks\n",
      "input_blocks.5.1.transformer_blocks.0\n",
      "input_blocks.5.1.transformer_blocks.0.attn1\n",
      "input_blocks.5.1.transformer_blocks.0.attn1.to_q\n",
      "input_blocks.5.1.transformer_blocks.0.attn1.to_k\n",
      "input_blocks.5.1.transformer_blocks.0.attn1.to_v\n",
      "input_blocks.5.1.transformer_blocks.0.attn1.to_out\n",
      "input_blocks.5.1.transformer_blocks.0.attn1.to_out.0\n",
      "input_blocks.5.1.transformer_blocks.0.attn1.to_out.1\n",
      "input_blocks.5.1.transformer_blocks.0.ff\n",
      "input_blocks.5.1.transformer_blocks.0.ff.net\n",
      "input_blocks.5.1.transformer_blocks.0.ff.net.0\n",
      "input_blocks.5.1.transformer_blocks.0.ff.net.0.proj\n",
      "input_blocks.5.1.transformer_blocks.0.ff.net.1\n",
      "input_blocks.5.1.transformer_blocks.0.ff.net.2\n",
      "input_blocks.5.1.transformer_blocks.0.attn2\n",
      "input_blocks.5.1.transformer_blocks.0.attn2.to_q\n",
      "input_blocks.5.1.transformer_blocks.0.attn2.to_k\n",
      "input_blocks.5.1.transformer_blocks.0.attn2.to_v\n",
      "input_blocks.5.1.transformer_blocks.0.attn2.to_out\n",
      "input_blocks.5.1.transformer_blocks.0.attn2.to_out.0\n",
      "input_blocks.5.1.transformer_blocks.0.attn2.to_out.1\n",
      "input_blocks.5.1.transformer_blocks.0.norm1\n",
      "input_blocks.5.1.transformer_blocks.0.norm2\n",
      "input_blocks.5.1.transformer_blocks.0.norm3\n",
      "input_blocks.5.1.proj_out\n",
      "input_blocks.5.1.time_stack\n",
      "input_blocks.5.1.time_stack.0\n",
      "input_blocks.5.1.time_stack.0.norm_in\n",
      "input_blocks.5.1.time_stack.0.ff_in\n",
      "input_blocks.5.1.time_stack.0.ff_in.net\n",
      "input_blocks.5.1.time_stack.0.ff_in.net.0\n",
      "input_blocks.5.1.time_stack.0.ff_in.net.0.proj\n",
      "input_blocks.5.1.time_stack.0.ff_in.net.1\n",
      "input_blocks.5.1.time_stack.0.ff_in.net.2\n",
      "input_blocks.5.1.time_stack.0.attn1\n",
      "input_blocks.5.1.time_stack.0.attn1.to_q\n",
      "input_blocks.5.1.time_stack.0.attn1.to_k\n",
      "input_blocks.5.1.time_stack.0.attn1.to_v\n",
      "input_blocks.5.1.time_stack.0.attn1.to_out\n",
      "input_blocks.5.1.time_stack.0.attn1.to_out.0\n",
      "input_blocks.5.1.time_stack.0.attn1.to_out.1\n",
      "input_blocks.5.1.time_stack.0.ff\n",
      "input_blocks.5.1.time_stack.0.ff.net\n",
      "input_blocks.5.1.time_stack.0.ff.net.0\n",
      "input_blocks.5.1.time_stack.0.ff.net.0.proj\n",
      "input_blocks.5.1.time_stack.0.ff.net.1\n",
      "input_blocks.5.1.time_stack.0.ff.net.2\n",
      "input_blocks.5.1.time_stack.0.norm2\n",
      "input_blocks.5.1.time_stack.0.attn2\n",
      "input_blocks.5.1.time_stack.0.attn2.to_q\n",
      "input_blocks.5.1.time_stack.0.attn2.to_k\n",
      "input_blocks.5.1.time_stack.0.attn2.to_v\n",
      "input_blocks.5.1.time_stack.0.attn2.to_out\n",
      "input_blocks.5.1.time_stack.0.attn2.to_out.0\n",
      "input_blocks.5.1.time_stack.0.attn2.to_out.1\n",
      "input_blocks.5.1.time_stack.0.norm1\n",
      "input_blocks.5.1.time_stack.0.norm3\n",
      "input_blocks.5.1.time_pos_embed\n",
      "input_blocks.5.1.time_pos_embed.0\n",
      "input_blocks.5.1.time_pos_embed.1\n",
      "input_blocks.5.1.time_pos_embed.2\n",
      "input_blocks.5.1.time_mixer\n",
      "input_blocks.6\n",
      "input_blocks.6.0\n",
      "input_blocks.6.0.op\n",
      "input_blocks.7\n",
      "input_blocks.7.0\n",
      "input_blocks.7.0.in_layers\n",
      "input_blocks.7.0.in_layers.0\n",
      "input_blocks.7.0.in_layers.1\n",
      "input_blocks.7.0.in_layers.2\n",
      "input_blocks.7.0.h_upd\n",
      "input_blocks.7.0.emb_layers\n",
      "input_blocks.7.0.emb_layers.0\n",
      "input_blocks.7.0.emb_layers.1\n",
      "input_blocks.7.0.out_layers\n",
      "input_blocks.7.0.out_layers.0\n",
      "input_blocks.7.0.out_layers.1\n",
      "input_blocks.7.0.out_layers.2\n",
      "input_blocks.7.0.out_layers.3\n",
      "input_blocks.7.0.skip_connection\n",
      "input_blocks.7.0.time_stack\n",
      "input_blocks.7.0.time_stack.in_layers\n",
      "input_blocks.7.0.time_stack.in_layers.0\n",
      "input_blocks.7.0.time_stack.in_layers.1\n",
      "input_blocks.7.0.time_stack.in_layers.2\n",
      "input_blocks.7.0.time_stack.h_upd\n",
      "input_blocks.7.0.time_stack.emb_layers\n",
      "input_blocks.7.0.time_stack.emb_layers.0\n",
      "input_blocks.7.0.time_stack.emb_layers.1\n",
      "input_blocks.7.0.time_stack.out_layers\n",
      "input_blocks.7.0.time_stack.out_layers.0\n",
      "input_blocks.7.0.time_stack.out_layers.1\n",
      "input_blocks.7.0.time_stack.out_layers.2\n",
      "input_blocks.7.0.time_stack.out_layers.3\n",
      "input_blocks.7.0.time_stack.skip_connection\n",
      "input_blocks.7.0.time_mixer\n",
      "input_blocks.7.1\n",
      "input_blocks.7.1.norm\n",
      "input_blocks.7.1.proj_in\n",
      "input_blocks.7.1.transformer_blocks\n",
      "input_blocks.7.1.transformer_blocks.0\n",
      "input_blocks.7.1.transformer_blocks.0.attn1\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_q\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_k\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_v\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_out\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_out.0\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_out.1\n",
      "input_blocks.7.1.transformer_blocks.0.ff\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.0\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.0.proj\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.1\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.2\n",
      "input_blocks.7.1.transformer_blocks.0.attn2\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_q\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_k\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_v\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_out\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_out.0\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_out.1\n",
      "input_blocks.7.1.transformer_blocks.0.norm1\n",
      "input_blocks.7.1.transformer_blocks.0.norm2\n",
      "input_blocks.7.1.transformer_blocks.0.norm3\n",
      "input_blocks.7.1.proj_out\n",
      "input_blocks.7.1.time_stack\n",
      "input_blocks.7.1.time_stack.0\n",
      "input_blocks.7.1.time_stack.0.norm_in\n",
      "input_blocks.7.1.time_stack.0.ff_in\n",
      "input_blocks.7.1.time_stack.0.ff_in.net\n",
      "input_blocks.7.1.time_stack.0.ff_in.net.0\n",
      "input_blocks.7.1.time_stack.0.ff_in.net.0.proj\n",
      "input_blocks.7.1.time_stack.0.ff_in.net.1\n",
      "input_blocks.7.1.time_stack.0.ff_in.net.2\n",
      "input_blocks.7.1.time_stack.0.attn1\n",
      "input_blocks.7.1.time_stack.0.attn1.to_q\n",
      "input_blocks.7.1.time_stack.0.attn1.to_k\n",
      "input_blocks.7.1.time_stack.0.attn1.to_v\n",
      "input_blocks.7.1.time_stack.0.attn1.to_out\n",
      "input_blocks.7.1.time_stack.0.attn1.to_out.0\n",
      "input_blocks.7.1.time_stack.0.attn1.to_out.1\n",
      "input_blocks.7.1.time_stack.0.ff\n",
      "input_blocks.7.1.time_stack.0.ff.net\n",
      "input_blocks.7.1.time_stack.0.ff.net.0\n",
      "input_blocks.7.1.time_stack.0.ff.net.0.proj\n",
      "input_blocks.7.1.time_stack.0.ff.net.1\n",
      "input_blocks.7.1.time_stack.0.ff.net.2\n",
      "input_blocks.7.1.time_stack.0.norm2\n",
      "input_blocks.7.1.time_stack.0.attn2\n",
      "input_blocks.7.1.time_stack.0.attn2.to_q\n",
      "input_blocks.7.1.time_stack.0.attn2.to_k\n",
      "input_blocks.7.1.time_stack.0.attn2.to_v\n",
      "input_blocks.7.1.time_stack.0.attn2.to_out\n",
      "input_blocks.7.1.time_stack.0.attn2.to_out.0\n",
      "input_blocks.7.1.time_stack.0.attn2.to_out.1\n",
      "input_blocks.7.1.time_stack.0.norm1\n",
      "input_blocks.7.1.time_stack.0.norm3\n",
      "input_blocks.7.1.time_pos_embed\n",
      "input_blocks.7.1.time_pos_embed.0\n",
      "input_blocks.7.1.time_pos_embed.1\n",
      "input_blocks.7.1.time_pos_embed.2\n",
      "input_blocks.7.1.time_mixer\n",
      "input_blocks.8\n",
      "input_blocks.8.0\n",
      "input_blocks.8.0.in_layers\n",
      "input_blocks.8.0.in_layers.0\n",
      "input_blocks.8.0.in_layers.1\n",
      "input_blocks.8.0.in_layers.2\n",
      "input_blocks.8.0.h_upd\n",
      "input_blocks.8.0.emb_layers\n",
      "input_blocks.8.0.emb_layers.0\n",
      "input_blocks.8.0.emb_layers.1\n",
      "input_blocks.8.0.out_layers\n",
      "input_blocks.8.0.out_layers.0\n",
      "input_blocks.8.0.out_layers.1\n",
      "input_blocks.8.0.out_layers.2\n",
      "input_blocks.8.0.out_layers.3\n",
      "input_blocks.8.0.skip_connection\n",
      "input_blocks.8.0.time_stack\n",
      "input_blocks.8.0.time_stack.in_layers\n",
      "input_blocks.8.0.time_stack.in_layers.0\n",
      "input_blocks.8.0.time_stack.in_layers.1\n",
      "input_blocks.8.0.time_stack.in_layers.2\n",
      "input_blocks.8.0.time_stack.h_upd\n",
      "input_blocks.8.0.time_stack.emb_layers\n",
      "input_blocks.8.0.time_stack.emb_layers.0\n",
      "input_blocks.8.0.time_stack.emb_layers.1\n",
      "input_blocks.8.0.time_stack.out_layers\n",
      "input_blocks.8.0.time_stack.out_layers.0\n",
      "input_blocks.8.0.time_stack.out_layers.1\n",
      "input_blocks.8.0.time_stack.out_layers.2\n",
      "input_blocks.8.0.time_stack.out_layers.3\n",
      "input_blocks.8.0.time_stack.skip_connection\n",
      "input_blocks.8.0.time_mixer\n",
      "input_blocks.8.1\n",
      "input_blocks.8.1.norm\n",
      "input_blocks.8.1.proj_in\n",
      "input_blocks.8.1.transformer_blocks\n",
      "input_blocks.8.1.transformer_blocks.0\n",
      "input_blocks.8.1.transformer_blocks.0.attn1\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_q\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_k\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_v\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_out\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_out.0\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_out.1\n",
      "input_blocks.8.1.transformer_blocks.0.ff\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.0\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.0.proj\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.1\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.2\n",
      "input_blocks.8.1.transformer_blocks.0.attn2\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_q\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_k\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_v\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_out\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_out.0\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_out.1\n",
      "input_blocks.8.1.transformer_blocks.0.norm1\n",
      "input_blocks.8.1.transformer_blocks.0.norm2\n",
      "input_blocks.8.1.transformer_blocks.0.norm3\n",
      "input_blocks.8.1.proj_out\n",
      "input_blocks.8.1.time_stack\n",
      "input_blocks.8.1.time_stack.0\n",
      "input_blocks.8.1.time_stack.0.norm_in\n",
      "input_blocks.8.1.time_stack.0.ff_in\n",
      "input_blocks.8.1.time_stack.0.ff_in.net\n",
      "input_blocks.8.1.time_stack.0.ff_in.net.0\n",
      "input_blocks.8.1.time_stack.0.ff_in.net.0.proj\n",
      "input_blocks.8.1.time_stack.0.ff_in.net.1\n",
      "input_blocks.8.1.time_stack.0.ff_in.net.2\n",
      "input_blocks.8.1.time_stack.0.attn1\n",
      "input_blocks.8.1.time_stack.0.attn1.to_q\n",
      "input_blocks.8.1.time_stack.0.attn1.to_k\n",
      "input_blocks.8.1.time_stack.0.attn1.to_v\n",
      "input_blocks.8.1.time_stack.0.attn1.to_out\n",
      "input_blocks.8.1.time_stack.0.attn1.to_out.0\n",
      "input_blocks.8.1.time_stack.0.attn1.to_out.1\n",
      "input_blocks.8.1.time_stack.0.ff\n",
      "input_blocks.8.1.time_stack.0.ff.net\n",
      "input_blocks.8.1.time_stack.0.ff.net.0\n",
      "input_blocks.8.1.time_stack.0.ff.net.0.proj\n",
      "input_blocks.8.1.time_stack.0.ff.net.1\n",
      "input_blocks.8.1.time_stack.0.ff.net.2\n",
      "input_blocks.8.1.time_stack.0.norm2\n",
      "input_blocks.8.1.time_stack.0.attn2\n",
      "input_blocks.8.1.time_stack.0.attn2.to_q\n",
      "input_blocks.8.1.time_stack.0.attn2.to_k\n",
      "input_blocks.8.1.time_stack.0.attn2.to_v\n",
      "input_blocks.8.1.time_stack.0.attn2.to_out\n",
      "input_blocks.8.1.time_stack.0.attn2.to_out.0\n",
      "input_blocks.8.1.time_stack.0.attn2.to_out.1\n",
      "input_blocks.8.1.time_stack.0.norm1\n",
      "input_blocks.8.1.time_stack.0.norm3\n",
      "input_blocks.8.1.time_pos_embed\n",
      "input_blocks.8.1.time_pos_embed.0\n",
      "input_blocks.8.1.time_pos_embed.1\n",
      "input_blocks.8.1.time_pos_embed.2\n",
      "input_blocks.8.1.time_mixer\n",
      "input_blocks.9\n",
      "input_blocks.9.0\n",
      "input_blocks.9.0.op\n",
      "input_blocks.10\n",
      "input_blocks.10.0\n",
      "input_blocks.10.0.in_layers\n",
      "input_blocks.10.0.in_layers.0\n",
      "input_blocks.10.0.in_layers.1\n",
      "input_blocks.10.0.in_layers.2\n",
      "input_blocks.10.0.h_upd\n",
      "input_blocks.10.0.emb_layers\n",
      "input_blocks.10.0.emb_layers.0\n",
      "input_blocks.10.0.emb_layers.1\n",
      "input_blocks.10.0.out_layers\n",
      "input_blocks.10.0.out_layers.0\n",
      "input_blocks.10.0.out_layers.1\n",
      "input_blocks.10.0.out_layers.2\n",
      "input_blocks.10.0.out_layers.3\n",
      "input_blocks.10.0.skip_connection\n",
      "input_blocks.10.0.time_stack\n",
      "input_blocks.10.0.time_stack.in_layers\n",
      "input_blocks.10.0.time_stack.in_layers.0\n",
      "input_blocks.10.0.time_stack.in_layers.1\n",
      "input_blocks.10.0.time_stack.in_layers.2\n",
      "input_blocks.10.0.time_stack.h_upd\n",
      "input_blocks.10.0.time_stack.emb_layers\n",
      "input_blocks.10.0.time_stack.emb_layers.0\n",
      "input_blocks.10.0.time_stack.emb_layers.1\n",
      "input_blocks.10.0.time_stack.out_layers\n",
      "input_blocks.10.0.time_stack.out_layers.0\n",
      "input_blocks.10.0.time_stack.out_layers.1\n",
      "input_blocks.10.0.time_stack.out_layers.2\n",
      "input_blocks.10.0.time_stack.out_layers.3\n",
      "input_blocks.10.0.time_stack.skip_connection\n",
      "input_blocks.10.0.time_mixer\n",
      "input_blocks.11\n",
      "input_blocks.11.0\n",
      "input_blocks.11.0.in_layers\n",
      "input_blocks.11.0.in_layers.0\n",
      "input_blocks.11.0.in_layers.1\n",
      "input_blocks.11.0.in_layers.2\n",
      "input_blocks.11.0.h_upd\n",
      "input_blocks.11.0.emb_layers\n",
      "input_blocks.11.0.emb_layers.0\n",
      "input_blocks.11.0.emb_layers.1\n",
      "input_blocks.11.0.out_layers\n",
      "input_blocks.11.0.out_layers.0\n",
      "input_blocks.11.0.out_layers.1\n",
      "input_blocks.11.0.out_layers.2\n",
      "input_blocks.11.0.out_layers.3\n",
      "input_blocks.11.0.skip_connection\n",
      "input_blocks.11.0.time_stack\n",
      "input_blocks.11.0.time_stack.in_layers\n",
      "input_blocks.11.0.time_stack.in_layers.0\n",
      "input_blocks.11.0.time_stack.in_layers.1\n",
      "input_blocks.11.0.time_stack.in_layers.2\n",
      "input_blocks.11.0.time_stack.h_upd\n",
      "input_blocks.11.0.time_stack.emb_layers\n",
      "input_blocks.11.0.time_stack.emb_layers.0\n",
      "input_blocks.11.0.time_stack.emb_layers.1\n",
      "input_blocks.11.0.time_stack.out_layers\n",
      "input_blocks.11.0.time_stack.out_layers.0\n",
      "input_blocks.11.0.time_stack.out_layers.1\n",
      "input_blocks.11.0.time_stack.out_layers.2\n",
      "input_blocks.11.0.time_stack.out_layers.3\n",
      "input_blocks.11.0.time_stack.skip_connection\n",
      "input_blocks.11.0.time_mixer\n",
      "middle_block\n",
      "middle_block.0\n",
      "middle_block.0.in_layers\n",
      "middle_block.0.in_layers.0\n",
      "middle_block.0.in_layers.1\n",
      "middle_block.0.in_layers.2\n",
      "middle_block.0.h_upd\n",
      "middle_block.0.emb_layers\n",
      "middle_block.0.emb_layers.0\n",
      "middle_block.0.emb_layers.1\n",
      "middle_block.0.out_layers\n",
      "middle_block.0.out_layers.0\n",
      "middle_block.0.out_layers.1\n",
      "middle_block.0.out_layers.2\n",
      "middle_block.0.out_layers.3\n",
      "middle_block.0.skip_connection\n",
      "middle_block.0.time_stack\n",
      "middle_block.0.time_stack.in_layers\n",
      "middle_block.0.time_stack.in_layers.0\n",
      "middle_block.0.time_stack.in_layers.1\n",
      "middle_block.0.time_stack.in_layers.2\n",
      "middle_block.0.time_stack.h_upd\n",
      "middle_block.0.time_stack.emb_layers\n",
      "middle_block.0.time_stack.emb_layers.0\n",
      "middle_block.0.time_stack.emb_layers.1\n",
      "middle_block.0.time_stack.out_layers\n",
      "middle_block.0.time_stack.out_layers.0\n",
      "middle_block.0.time_stack.out_layers.1\n",
      "middle_block.0.time_stack.out_layers.2\n",
      "middle_block.0.time_stack.out_layers.3\n",
      "middle_block.0.time_stack.skip_connection\n",
      "middle_block.0.time_mixer\n",
      "middle_block.1\n",
      "middle_block.1.norm\n",
      "middle_block.1.proj_in\n",
      "middle_block.1.transformer_blocks\n",
      "middle_block.1.transformer_blocks.0\n",
      "middle_block.1.transformer_blocks.0.attn1\n",
      "middle_block.1.transformer_blocks.0.attn1.to_q\n",
      "middle_block.1.transformer_blocks.0.attn1.to_k\n",
      "middle_block.1.transformer_blocks.0.attn1.to_v\n",
      "middle_block.1.transformer_blocks.0.attn1.to_out\n",
      "middle_block.1.transformer_blocks.0.attn1.to_out.0\n",
      "middle_block.1.transformer_blocks.0.attn1.to_out.1\n",
      "middle_block.1.transformer_blocks.0.ff\n",
      "middle_block.1.transformer_blocks.0.ff.net\n",
      "middle_block.1.transformer_blocks.0.ff.net.0\n",
      "middle_block.1.transformer_blocks.0.ff.net.0.proj\n",
      "middle_block.1.transformer_blocks.0.ff.net.1\n",
      "middle_block.1.transformer_blocks.0.ff.net.2\n",
      "middle_block.1.transformer_blocks.0.attn2\n",
      "middle_block.1.transformer_blocks.0.attn2.to_q\n",
      "middle_block.1.transformer_blocks.0.attn2.to_k\n",
      "middle_block.1.transformer_blocks.0.attn2.to_v\n",
      "middle_block.1.transformer_blocks.0.attn2.to_out\n",
      "middle_block.1.transformer_blocks.0.attn2.to_out.0\n",
      "middle_block.1.transformer_blocks.0.attn2.to_out.1\n",
      "middle_block.1.transformer_blocks.0.norm1\n",
      "middle_block.1.transformer_blocks.0.norm2\n",
      "middle_block.1.transformer_blocks.0.norm3\n",
      "middle_block.1.proj_out\n",
      "middle_block.1.time_stack\n",
      "middle_block.1.time_stack.0\n",
      "middle_block.1.time_stack.0.norm_in\n",
      "middle_block.1.time_stack.0.ff_in\n",
      "middle_block.1.time_stack.0.ff_in.net\n",
      "middle_block.1.time_stack.0.ff_in.net.0\n",
      "middle_block.1.time_stack.0.ff_in.net.0.proj\n",
      "middle_block.1.time_stack.0.ff_in.net.1\n",
      "middle_block.1.time_stack.0.ff_in.net.2\n",
      "middle_block.1.time_stack.0.attn1\n",
      "middle_block.1.time_stack.0.attn1.to_q\n",
      "middle_block.1.time_stack.0.attn1.to_k\n",
      "middle_block.1.time_stack.0.attn1.to_v\n",
      "middle_block.1.time_stack.0.attn1.to_out\n",
      "middle_block.1.time_stack.0.attn1.to_out.0\n",
      "middle_block.1.time_stack.0.attn1.to_out.1\n",
      "middle_block.1.time_stack.0.ff\n",
      "middle_block.1.time_stack.0.ff.net\n",
      "middle_block.1.time_stack.0.ff.net.0\n",
      "middle_block.1.time_stack.0.ff.net.0.proj\n",
      "middle_block.1.time_stack.0.ff.net.1\n",
      "middle_block.1.time_stack.0.ff.net.2\n",
      "middle_block.1.time_stack.0.norm2\n",
      "middle_block.1.time_stack.0.attn2\n",
      "middle_block.1.time_stack.0.attn2.to_q\n",
      "middle_block.1.time_stack.0.attn2.to_k\n",
      "middle_block.1.time_stack.0.attn2.to_v\n",
      "middle_block.1.time_stack.0.attn2.to_out\n",
      "middle_block.1.time_stack.0.attn2.to_out.0\n",
      "middle_block.1.time_stack.0.attn2.to_out.1\n",
      "middle_block.1.time_stack.0.norm1\n",
      "middle_block.1.time_stack.0.norm3\n",
      "middle_block.1.time_pos_embed\n",
      "middle_block.1.time_pos_embed.0\n",
      "middle_block.1.time_pos_embed.1\n",
      "middle_block.1.time_pos_embed.2\n",
      "middle_block.1.time_mixer\n",
      "middle_block.2\n",
      "middle_block.2.in_layers\n",
      "middle_block.2.in_layers.0\n",
      "middle_block.2.in_layers.1\n",
      "middle_block.2.in_layers.2\n",
      "middle_block.2.h_upd\n",
      "middle_block.2.emb_layers\n",
      "middle_block.2.emb_layers.0\n",
      "middle_block.2.emb_layers.1\n",
      "middle_block.2.out_layers\n",
      "middle_block.2.out_layers.0\n",
      "middle_block.2.out_layers.1\n",
      "middle_block.2.out_layers.2\n",
      "middle_block.2.out_layers.3\n",
      "middle_block.2.skip_connection\n",
      "middle_block.2.time_stack\n",
      "middle_block.2.time_stack.in_layers\n",
      "middle_block.2.time_stack.in_layers.0\n",
      "middle_block.2.time_stack.in_layers.1\n",
      "middle_block.2.time_stack.in_layers.2\n",
      "middle_block.2.time_stack.h_upd\n",
      "middle_block.2.time_stack.emb_layers\n",
      "middle_block.2.time_stack.emb_layers.0\n",
      "middle_block.2.time_stack.emb_layers.1\n",
      "middle_block.2.time_stack.out_layers\n",
      "middle_block.2.time_stack.out_layers.0\n",
      "middle_block.2.time_stack.out_layers.1\n",
      "middle_block.2.time_stack.out_layers.2\n",
      "middle_block.2.time_stack.out_layers.3\n",
      "middle_block.2.time_stack.skip_connection\n",
      "middle_block.2.time_mixer\n",
      "output_blocks\n",
      "output_blocks.0\n",
      "output_blocks.0.0\n",
      "output_blocks.0.0.in_layers\n",
      "output_blocks.0.0.in_layers.0\n",
      "output_blocks.0.0.in_layers.1\n",
      "output_blocks.0.0.in_layers.2\n",
      "output_blocks.0.0.h_upd\n",
      "output_blocks.0.0.emb_layers\n",
      "output_blocks.0.0.emb_layers.0\n",
      "output_blocks.0.0.emb_layers.1\n",
      "output_blocks.0.0.out_layers\n",
      "output_blocks.0.0.out_layers.0\n",
      "output_blocks.0.0.out_layers.1\n",
      "output_blocks.0.0.out_layers.2\n",
      "output_blocks.0.0.out_layers.3\n",
      "output_blocks.0.0.skip_connection\n",
      "output_blocks.0.0.time_stack\n",
      "output_blocks.0.0.time_stack.in_layers\n",
      "output_blocks.0.0.time_stack.in_layers.0\n",
      "output_blocks.0.0.time_stack.in_layers.1\n",
      "output_blocks.0.0.time_stack.in_layers.2\n",
      "output_blocks.0.0.time_stack.h_upd\n",
      "output_blocks.0.0.time_stack.emb_layers\n",
      "output_blocks.0.0.time_stack.emb_layers.0\n",
      "output_blocks.0.0.time_stack.emb_layers.1\n",
      "output_blocks.0.0.time_stack.out_layers\n",
      "output_blocks.0.0.time_stack.out_layers.0\n",
      "output_blocks.0.0.time_stack.out_layers.1\n",
      "output_blocks.0.0.time_stack.out_layers.2\n",
      "output_blocks.0.0.time_stack.out_layers.3\n",
      "output_blocks.0.0.time_stack.skip_connection\n",
      "output_blocks.0.0.time_mixer\n",
      "output_blocks.1\n",
      "output_blocks.1.0\n",
      "output_blocks.1.0.in_layers\n",
      "output_blocks.1.0.in_layers.0\n",
      "output_blocks.1.0.in_layers.1\n",
      "output_blocks.1.0.in_layers.2\n",
      "output_blocks.1.0.h_upd\n",
      "output_blocks.1.0.emb_layers\n",
      "output_blocks.1.0.emb_layers.0\n",
      "output_blocks.1.0.emb_layers.1\n",
      "output_blocks.1.0.out_layers\n",
      "output_blocks.1.0.out_layers.0\n",
      "output_blocks.1.0.out_layers.1\n",
      "output_blocks.1.0.out_layers.2\n",
      "output_blocks.1.0.out_layers.3\n",
      "output_blocks.1.0.skip_connection\n",
      "output_blocks.1.0.time_stack\n",
      "output_blocks.1.0.time_stack.in_layers\n",
      "output_blocks.1.0.time_stack.in_layers.0\n",
      "output_blocks.1.0.time_stack.in_layers.1\n",
      "output_blocks.1.0.time_stack.in_layers.2\n",
      "output_blocks.1.0.time_stack.h_upd\n",
      "output_blocks.1.0.time_stack.emb_layers\n",
      "output_blocks.1.0.time_stack.emb_layers.0\n",
      "output_blocks.1.0.time_stack.emb_layers.1\n",
      "output_blocks.1.0.time_stack.out_layers\n",
      "output_blocks.1.0.time_stack.out_layers.0\n",
      "output_blocks.1.0.time_stack.out_layers.1\n",
      "output_blocks.1.0.time_stack.out_layers.2\n",
      "output_blocks.1.0.time_stack.out_layers.3\n",
      "output_blocks.1.0.time_stack.skip_connection\n",
      "output_blocks.1.0.time_mixer\n",
      "output_blocks.2\n",
      "output_blocks.2.0\n",
      "output_blocks.2.0.in_layers\n",
      "output_blocks.2.0.in_layers.0\n",
      "output_blocks.2.0.in_layers.1\n",
      "output_blocks.2.0.in_layers.2\n",
      "output_blocks.2.0.h_upd\n",
      "output_blocks.2.0.emb_layers\n",
      "output_blocks.2.0.emb_layers.0\n",
      "output_blocks.2.0.emb_layers.1\n",
      "output_blocks.2.0.out_layers\n",
      "output_blocks.2.0.out_layers.0\n",
      "output_blocks.2.0.out_layers.1\n",
      "output_blocks.2.0.out_layers.2\n",
      "output_blocks.2.0.out_layers.3\n",
      "output_blocks.2.0.skip_connection\n",
      "output_blocks.2.0.time_stack\n",
      "output_blocks.2.0.time_stack.in_layers\n",
      "output_blocks.2.0.time_stack.in_layers.0\n",
      "output_blocks.2.0.time_stack.in_layers.1\n",
      "output_blocks.2.0.time_stack.in_layers.2\n",
      "output_blocks.2.0.time_stack.h_upd\n",
      "output_blocks.2.0.time_stack.emb_layers\n",
      "output_blocks.2.0.time_stack.emb_layers.0\n",
      "output_blocks.2.0.time_stack.emb_layers.1\n",
      "output_blocks.2.0.time_stack.out_layers\n",
      "output_blocks.2.0.time_stack.out_layers.0\n",
      "output_blocks.2.0.time_stack.out_layers.1\n",
      "output_blocks.2.0.time_stack.out_layers.2\n",
      "output_blocks.2.0.time_stack.out_layers.3\n",
      "output_blocks.2.0.time_stack.skip_connection\n",
      "output_blocks.2.0.time_mixer\n",
      "output_blocks.2.1\n",
      "output_blocks.2.1.conv\n",
      "output_blocks.3\n",
      "output_blocks.3.0\n",
      "output_blocks.3.0.in_layers\n",
      "output_blocks.3.0.in_layers.0\n",
      "output_blocks.3.0.in_layers.1\n",
      "output_blocks.3.0.in_layers.2\n",
      "output_blocks.3.0.h_upd\n",
      "output_blocks.3.0.emb_layers\n",
      "output_blocks.3.0.emb_layers.0\n",
      "output_blocks.3.0.emb_layers.1\n",
      "output_blocks.3.0.out_layers\n",
      "output_blocks.3.0.out_layers.0\n",
      "output_blocks.3.0.out_layers.1\n",
      "output_blocks.3.0.out_layers.2\n",
      "output_blocks.3.0.out_layers.3\n",
      "output_blocks.3.0.skip_connection\n",
      "output_blocks.3.0.time_stack\n",
      "output_blocks.3.0.time_stack.in_layers\n",
      "output_blocks.3.0.time_stack.in_layers.0\n",
      "output_blocks.3.0.time_stack.in_layers.1\n",
      "output_blocks.3.0.time_stack.in_layers.2\n",
      "output_blocks.3.0.time_stack.h_upd\n",
      "output_blocks.3.0.time_stack.emb_layers\n",
      "output_blocks.3.0.time_stack.emb_layers.0\n",
      "output_blocks.3.0.time_stack.emb_layers.1\n",
      "output_blocks.3.0.time_stack.out_layers\n",
      "output_blocks.3.0.time_stack.out_layers.0\n",
      "output_blocks.3.0.time_stack.out_layers.1\n",
      "output_blocks.3.0.time_stack.out_layers.2\n",
      "output_blocks.3.0.time_stack.out_layers.3\n",
      "output_blocks.3.0.time_stack.skip_connection\n",
      "output_blocks.3.0.time_mixer\n",
      "output_blocks.3.1\n",
      "output_blocks.3.1.norm\n",
      "output_blocks.3.1.proj_in\n",
      "output_blocks.3.1.transformer_blocks\n",
      "output_blocks.3.1.transformer_blocks.0\n",
      "output_blocks.3.1.transformer_blocks.0.attn1\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.3.1.transformer_blocks.0.ff\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.3.1.transformer_blocks.0.attn2\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.3.1.transformer_blocks.0.norm1\n",
      "output_blocks.3.1.transformer_blocks.0.norm2\n",
      "output_blocks.3.1.transformer_blocks.0.norm3\n",
      "output_blocks.3.1.proj_out\n",
      "output_blocks.3.1.time_stack\n",
      "output_blocks.3.1.time_stack.0\n",
      "output_blocks.3.1.time_stack.0.norm_in\n",
      "output_blocks.3.1.time_stack.0.ff_in\n",
      "output_blocks.3.1.time_stack.0.ff_in.net\n",
      "output_blocks.3.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.3.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.3.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.3.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.3.1.time_stack.0.attn1\n",
      "output_blocks.3.1.time_stack.0.attn1.to_q\n",
      "output_blocks.3.1.time_stack.0.attn1.to_k\n",
      "output_blocks.3.1.time_stack.0.attn1.to_v\n",
      "output_blocks.3.1.time_stack.0.attn1.to_out\n",
      "output_blocks.3.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.3.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.3.1.time_stack.0.ff\n",
      "output_blocks.3.1.time_stack.0.ff.net\n",
      "output_blocks.3.1.time_stack.0.ff.net.0\n",
      "output_blocks.3.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.3.1.time_stack.0.ff.net.1\n",
      "output_blocks.3.1.time_stack.0.ff.net.2\n",
      "output_blocks.3.1.time_stack.0.norm2\n",
      "output_blocks.3.1.time_stack.0.attn2\n",
      "output_blocks.3.1.time_stack.0.attn2.to_q\n",
      "output_blocks.3.1.time_stack.0.attn2.to_k\n",
      "output_blocks.3.1.time_stack.0.attn2.to_v\n",
      "output_blocks.3.1.time_stack.0.attn2.to_out\n",
      "output_blocks.3.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.3.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.3.1.time_stack.0.norm1\n",
      "output_blocks.3.1.time_stack.0.norm3\n",
      "output_blocks.3.1.time_pos_embed\n",
      "output_blocks.3.1.time_pos_embed.0\n",
      "output_blocks.3.1.time_pos_embed.1\n",
      "output_blocks.3.1.time_pos_embed.2\n",
      "output_blocks.3.1.time_mixer\n",
      "output_blocks.4\n",
      "output_blocks.4.0\n",
      "output_blocks.4.0.in_layers\n",
      "output_blocks.4.0.in_layers.0\n",
      "output_blocks.4.0.in_layers.1\n",
      "output_blocks.4.0.in_layers.2\n",
      "output_blocks.4.0.h_upd\n",
      "output_blocks.4.0.emb_layers\n",
      "output_blocks.4.0.emb_layers.0\n",
      "output_blocks.4.0.emb_layers.1\n",
      "output_blocks.4.0.out_layers\n",
      "output_blocks.4.0.out_layers.0\n",
      "output_blocks.4.0.out_layers.1\n",
      "output_blocks.4.0.out_layers.2\n",
      "output_blocks.4.0.out_layers.3\n",
      "output_blocks.4.0.skip_connection\n",
      "output_blocks.4.0.time_stack\n",
      "output_blocks.4.0.time_stack.in_layers\n",
      "output_blocks.4.0.time_stack.in_layers.0\n",
      "output_blocks.4.0.time_stack.in_layers.1\n",
      "output_blocks.4.0.time_stack.in_layers.2\n",
      "output_blocks.4.0.time_stack.h_upd\n",
      "output_blocks.4.0.time_stack.emb_layers\n",
      "output_blocks.4.0.time_stack.emb_layers.0\n",
      "output_blocks.4.0.time_stack.emb_layers.1\n",
      "output_blocks.4.0.time_stack.out_layers\n",
      "output_blocks.4.0.time_stack.out_layers.0\n",
      "output_blocks.4.0.time_stack.out_layers.1\n",
      "output_blocks.4.0.time_stack.out_layers.2\n",
      "output_blocks.4.0.time_stack.out_layers.3\n",
      "output_blocks.4.0.time_stack.skip_connection\n",
      "output_blocks.4.0.time_mixer\n",
      "output_blocks.4.1\n",
      "output_blocks.4.1.norm\n",
      "output_blocks.4.1.proj_in\n",
      "output_blocks.4.1.transformer_blocks\n",
      "output_blocks.4.1.transformer_blocks.0\n",
      "output_blocks.4.1.transformer_blocks.0.attn1\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.4.1.transformer_blocks.0.ff\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.4.1.transformer_blocks.0.attn2\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.4.1.transformer_blocks.0.norm1\n",
      "output_blocks.4.1.transformer_blocks.0.norm2\n",
      "output_blocks.4.1.transformer_blocks.0.norm3\n",
      "output_blocks.4.1.proj_out\n",
      "output_blocks.4.1.time_stack\n",
      "output_blocks.4.1.time_stack.0\n",
      "output_blocks.4.1.time_stack.0.norm_in\n",
      "output_blocks.4.1.time_stack.0.ff_in\n",
      "output_blocks.4.1.time_stack.0.ff_in.net\n",
      "output_blocks.4.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.4.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.4.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.4.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.4.1.time_stack.0.attn1\n",
      "output_blocks.4.1.time_stack.0.attn1.to_q\n",
      "output_blocks.4.1.time_stack.0.attn1.to_k\n",
      "output_blocks.4.1.time_stack.0.attn1.to_v\n",
      "output_blocks.4.1.time_stack.0.attn1.to_out\n",
      "output_blocks.4.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.4.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.4.1.time_stack.0.ff\n",
      "output_blocks.4.1.time_stack.0.ff.net\n",
      "output_blocks.4.1.time_stack.0.ff.net.0\n",
      "output_blocks.4.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.4.1.time_stack.0.ff.net.1\n",
      "output_blocks.4.1.time_stack.0.ff.net.2\n",
      "output_blocks.4.1.time_stack.0.norm2\n",
      "output_blocks.4.1.time_stack.0.attn2\n",
      "output_blocks.4.1.time_stack.0.attn2.to_q\n",
      "output_blocks.4.1.time_stack.0.attn2.to_k\n",
      "output_blocks.4.1.time_stack.0.attn2.to_v\n",
      "output_blocks.4.1.time_stack.0.attn2.to_out\n",
      "output_blocks.4.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.4.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.4.1.time_stack.0.norm1\n",
      "output_blocks.4.1.time_stack.0.norm3\n",
      "output_blocks.4.1.time_pos_embed\n",
      "output_blocks.4.1.time_pos_embed.0\n",
      "output_blocks.4.1.time_pos_embed.1\n",
      "output_blocks.4.1.time_pos_embed.2\n",
      "output_blocks.4.1.time_mixer\n",
      "output_blocks.5\n",
      "output_blocks.5.0\n",
      "output_blocks.5.0.in_layers\n",
      "output_blocks.5.0.in_layers.0\n",
      "output_blocks.5.0.in_layers.1\n",
      "output_blocks.5.0.in_layers.2\n",
      "output_blocks.5.0.h_upd\n",
      "output_blocks.5.0.emb_layers\n",
      "output_blocks.5.0.emb_layers.0\n",
      "output_blocks.5.0.emb_layers.1\n",
      "output_blocks.5.0.out_layers\n",
      "output_blocks.5.0.out_layers.0\n",
      "output_blocks.5.0.out_layers.1\n",
      "output_blocks.5.0.out_layers.2\n",
      "output_blocks.5.0.out_layers.3\n",
      "output_blocks.5.0.skip_connection\n",
      "output_blocks.5.0.time_stack\n",
      "output_blocks.5.0.time_stack.in_layers\n",
      "output_blocks.5.0.time_stack.in_layers.0\n",
      "output_blocks.5.0.time_stack.in_layers.1\n",
      "output_blocks.5.0.time_stack.in_layers.2\n",
      "output_blocks.5.0.time_stack.h_upd\n",
      "output_blocks.5.0.time_stack.emb_layers\n",
      "output_blocks.5.0.time_stack.emb_layers.0\n",
      "output_blocks.5.0.time_stack.emb_layers.1\n",
      "output_blocks.5.0.time_stack.out_layers\n",
      "output_blocks.5.0.time_stack.out_layers.0\n",
      "output_blocks.5.0.time_stack.out_layers.1\n",
      "output_blocks.5.0.time_stack.out_layers.2\n",
      "output_blocks.5.0.time_stack.out_layers.3\n",
      "output_blocks.5.0.time_stack.skip_connection\n",
      "output_blocks.5.0.time_mixer\n",
      "output_blocks.5.1\n",
      "output_blocks.5.1.norm\n",
      "output_blocks.5.1.proj_in\n",
      "output_blocks.5.1.transformer_blocks\n",
      "output_blocks.5.1.transformer_blocks.0\n",
      "output_blocks.5.1.transformer_blocks.0.attn1\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.5.1.transformer_blocks.0.ff\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.5.1.transformer_blocks.0.attn2\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.5.1.transformer_blocks.0.norm1\n",
      "output_blocks.5.1.transformer_blocks.0.norm2\n",
      "output_blocks.5.1.transformer_blocks.0.norm3\n",
      "output_blocks.5.1.proj_out\n",
      "output_blocks.5.1.time_stack\n",
      "output_blocks.5.1.time_stack.0\n",
      "output_blocks.5.1.time_stack.0.norm_in\n",
      "output_blocks.5.1.time_stack.0.ff_in\n",
      "output_blocks.5.1.time_stack.0.ff_in.net\n",
      "output_blocks.5.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.5.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.5.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.5.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.5.1.time_stack.0.attn1\n",
      "output_blocks.5.1.time_stack.0.attn1.to_q\n",
      "output_blocks.5.1.time_stack.0.attn1.to_k\n",
      "output_blocks.5.1.time_stack.0.attn1.to_v\n",
      "output_blocks.5.1.time_stack.0.attn1.to_out\n",
      "output_blocks.5.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.5.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.5.1.time_stack.0.ff\n",
      "output_blocks.5.1.time_stack.0.ff.net\n",
      "output_blocks.5.1.time_stack.0.ff.net.0\n",
      "output_blocks.5.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.5.1.time_stack.0.ff.net.1\n",
      "output_blocks.5.1.time_stack.0.ff.net.2\n",
      "output_blocks.5.1.time_stack.0.norm2\n",
      "output_blocks.5.1.time_stack.0.attn2\n",
      "output_blocks.5.1.time_stack.0.attn2.to_q\n",
      "output_blocks.5.1.time_stack.0.attn2.to_k\n",
      "output_blocks.5.1.time_stack.0.attn2.to_v\n",
      "output_blocks.5.1.time_stack.0.attn2.to_out\n",
      "output_blocks.5.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.5.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.5.1.time_stack.0.norm1\n",
      "output_blocks.5.1.time_stack.0.norm3\n",
      "output_blocks.5.1.time_pos_embed\n",
      "output_blocks.5.1.time_pos_embed.0\n",
      "output_blocks.5.1.time_pos_embed.1\n",
      "output_blocks.5.1.time_pos_embed.2\n",
      "output_blocks.5.1.time_mixer\n",
      "output_blocks.5.2\n",
      "output_blocks.5.2.conv\n",
      "output_blocks.6\n",
      "output_blocks.6.0\n",
      "output_blocks.6.0.in_layers\n",
      "output_blocks.6.0.in_layers.0\n",
      "output_blocks.6.0.in_layers.1\n",
      "output_blocks.6.0.in_layers.2\n",
      "output_blocks.6.0.h_upd\n",
      "output_blocks.6.0.emb_layers\n",
      "output_blocks.6.0.emb_layers.0\n",
      "output_blocks.6.0.emb_layers.1\n",
      "output_blocks.6.0.out_layers\n",
      "output_blocks.6.0.out_layers.0\n",
      "output_blocks.6.0.out_layers.1\n",
      "output_blocks.6.0.out_layers.2\n",
      "output_blocks.6.0.out_layers.3\n",
      "output_blocks.6.0.skip_connection\n",
      "output_blocks.6.0.time_stack\n",
      "output_blocks.6.0.time_stack.in_layers\n",
      "output_blocks.6.0.time_stack.in_layers.0\n",
      "output_blocks.6.0.time_stack.in_layers.1\n",
      "output_blocks.6.0.time_stack.in_layers.2\n",
      "output_blocks.6.0.time_stack.h_upd\n",
      "output_blocks.6.0.time_stack.emb_layers\n",
      "output_blocks.6.0.time_stack.emb_layers.0\n",
      "output_blocks.6.0.time_stack.emb_layers.1\n",
      "output_blocks.6.0.time_stack.out_layers\n",
      "output_blocks.6.0.time_stack.out_layers.0\n",
      "output_blocks.6.0.time_stack.out_layers.1\n",
      "output_blocks.6.0.time_stack.out_layers.2\n",
      "output_blocks.6.0.time_stack.out_layers.3\n",
      "output_blocks.6.0.time_stack.skip_connection\n",
      "output_blocks.6.0.time_mixer\n",
      "output_blocks.6.1\n",
      "output_blocks.6.1.norm\n",
      "output_blocks.6.1.proj_in\n",
      "output_blocks.6.1.transformer_blocks\n",
      "output_blocks.6.1.transformer_blocks.0\n",
      "output_blocks.6.1.transformer_blocks.0.attn1\n",
      "output_blocks.6.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.6.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.6.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.6.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.6.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.6.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.6.1.transformer_blocks.0.ff\n",
      "output_blocks.6.1.transformer_blocks.0.ff.net\n",
      "output_blocks.6.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.6.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.6.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.6.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.6.1.transformer_blocks.0.attn2\n",
      "output_blocks.6.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.6.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.6.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.6.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.6.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.6.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.6.1.transformer_blocks.0.norm1\n",
      "output_blocks.6.1.transformer_blocks.0.norm2\n",
      "output_blocks.6.1.transformer_blocks.0.norm3\n",
      "output_blocks.6.1.proj_out\n",
      "output_blocks.6.1.time_stack\n",
      "output_blocks.6.1.time_stack.0\n",
      "output_blocks.6.1.time_stack.0.norm_in\n",
      "output_blocks.6.1.time_stack.0.ff_in\n",
      "output_blocks.6.1.time_stack.0.ff_in.net\n",
      "output_blocks.6.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.6.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.6.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.6.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.6.1.time_stack.0.attn1\n",
      "output_blocks.6.1.time_stack.0.attn1.to_q\n",
      "output_blocks.6.1.time_stack.0.attn1.to_k\n",
      "output_blocks.6.1.time_stack.0.attn1.to_v\n",
      "output_blocks.6.1.time_stack.0.attn1.to_out\n",
      "output_blocks.6.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.6.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.6.1.time_stack.0.ff\n",
      "output_blocks.6.1.time_stack.0.ff.net\n",
      "output_blocks.6.1.time_stack.0.ff.net.0\n",
      "output_blocks.6.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.6.1.time_stack.0.ff.net.1\n",
      "output_blocks.6.1.time_stack.0.ff.net.2\n",
      "output_blocks.6.1.time_stack.0.norm2\n",
      "output_blocks.6.1.time_stack.0.attn2\n",
      "output_blocks.6.1.time_stack.0.attn2.to_q\n",
      "output_blocks.6.1.time_stack.0.attn2.to_k\n",
      "output_blocks.6.1.time_stack.0.attn2.to_v\n",
      "output_blocks.6.1.time_stack.0.attn2.to_out\n",
      "output_blocks.6.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.6.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.6.1.time_stack.0.norm1\n",
      "output_blocks.6.1.time_stack.0.norm3\n",
      "output_blocks.6.1.time_pos_embed\n",
      "output_blocks.6.1.time_pos_embed.0\n",
      "output_blocks.6.1.time_pos_embed.1\n",
      "output_blocks.6.1.time_pos_embed.2\n",
      "output_blocks.6.1.time_mixer\n",
      "output_blocks.7\n",
      "output_blocks.7.0\n",
      "output_blocks.7.0.in_layers\n",
      "output_blocks.7.0.in_layers.0\n",
      "output_blocks.7.0.in_layers.1\n",
      "output_blocks.7.0.in_layers.2\n",
      "output_blocks.7.0.h_upd\n",
      "output_blocks.7.0.emb_layers\n",
      "output_blocks.7.0.emb_layers.0\n",
      "output_blocks.7.0.emb_layers.1\n",
      "output_blocks.7.0.out_layers\n",
      "output_blocks.7.0.out_layers.0\n",
      "output_blocks.7.0.out_layers.1\n",
      "output_blocks.7.0.out_layers.2\n",
      "output_blocks.7.0.out_layers.3\n",
      "output_blocks.7.0.skip_connection\n",
      "output_blocks.7.0.time_stack\n",
      "output_blocks.7.0.time_stack.in_layers\n",
      "output_blocks.7.0.time_stack.in_layers.0\n",
      "output_blocks.7.0.time_stack.in_layers.1\n",
      "output_blocks.7.0.time_stack.in_layers.2\n",
      "output_blocks.7.0.time_stack.h_upd\n",
      "output_blocks.7.0.time_stack.emb_layers\n",
      "output_blocks.7.0.time_stack.emb_layers.0\n",
      "output_blocks.7.0.time_stack.emb_layers.1\n",
      "output_blocks.7.0.time_stack.out_layers\n",
      "output_blocks.7.0.time_stack.out_layers.0\n",
      "output_blocks.7.0.time_stack.out_layers.1\n",
      "output_blocks.7.0.time_stack.out_layers.2\n",
      "output_blocks.7.0.time_stack.out_layers.3\n",
      "output_blocks.7.0.time_stack.skip_connection\n",
      "output_blocks.7.0.time_mixer\n",
      "output_blocks.7.1\n",
      "output_blocks.7.1.norm\n",
      "output_blocks.7.1.proj_in\n",
      "output_blocks.7.1.transformer_blocks\n",
      "output_blocks.7.1.transformer_blocks.0\n",
      "output_blocks.7.1.transformer_blocks.0.attn1\n",
      "output_blocks.7.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.7.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.7.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.7.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.7.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.7.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.7.1.transformer_blocks.0.ff\n",
      "output_blocks.7.1.transformer_blocks.0.ff.net\n",
      "output_blocks.7.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.7.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.7.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.7.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.7.1.transformer_blocks.0.attn2\n",
      "output_blocks.7.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.7.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.7.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.7.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.7.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.7.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.7.1.transformer_blocks.0.norm1\n",
      "output_blocks.7.1.transformer_blocks.0.norm2\n",
      "output_blocks.7.1.transformer_blocks.0.norm3\n",
      "output_blocks.7.1.proj_out\n",
      "output_blocks.7.1.time_stack\n",
      "output_blocks.7.1.time_stack.0\n",
      "output_blocks.7.1.time_stack.0.norm_in\n",
      "output_blocks.7.1.time_stack.0.ff_in\n",
      "output_blocks.7.1.time_stack.0.ff_in.net\n",
      "output_blocks.7.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.7.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.7.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.7.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.7.1.time_stack.0.attn1\n",
      "output_blocks.7.1.time_stack.0.attn1.to_q\n",
      "output_blocks.7.1.time_stack.0.attn1.to_k\n",
      "output_blocks.7.1.time_stack.0.attn1.to_v\n",
      "output_blocks.7.1.time_stack.0.attn1.to_out\n",
      "output_blocks.7.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.7.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.7.1.time_stack.0.ff\n",
      "output_blocks.7.1.time_stack.0.ff.net\n",
      "output_blocks.7.1.time_stack.0.ff.net.0\n",
      "output_blocks.7.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.7.1.time_stack.0.ff.net.1\n",
      "output_blocks.7.1.time_stack.0.ff.net.2\n",
      "output_blocks.7.1.time_stack.0.norm2\n",
      "output_blocks.7.1.time_stack.0.attn2\n",
      "output_blocks.7.1.time_stack.0.attn2.to_q\n",
      "output_blocks.7.1.time_stack.0.attn2.to_k\n",
      "output_blocks.7.1.time_stack.0.attn2.to_v\n",
      "output_blocks.7.1.time_stack.0.attn2.to_out\n",
      "output_blocks.7.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.7.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.7.1.time_stack.0.norm1\n",
      "output_blocks.7.1.time_stack.0.norm3\n",
      "output_blocks.7.1.time_pos_embed\n",
      "output_blocks.7.1.time_pos_embed.0\n",
      "output_blocks.7.1.time_pos_embed.1\n",
      "output_blocks.7.1.time_pos_embed.2\n",
      "output_blocks.7.1.time_mixer\n",
      "output_blocks.8\n",
      "output_blocks.8.0\n",
      "output_blocks.8.0.in_layers\n",
      "output_blocks.8.0.in_layers.0\n",
      "output_blocks.8.0.in_layers.1\n",
      "output_blocks.8.0.in_layers.2\n",
      "output_blocks.8.0.h_upd\n",
      "output_blocks.8.0.emb_layers\n",
      "output_blocks.8.0.emb_layers.0\n",
      "output_blocks.8.0.emb_layers.1\n",
      "output_blocks.8.0.out_layers\n",
      "output_blocks.8.0.out_layers.0\n",
      "output_blocks.8.0.out_layers.1\n",
      "output_blocks.8.0.out_layers.2\n",
      "output_blocks.8.0.out_layers.3\n",
      "output_blocks.8.0.skip_connection\n",
      "output_blocks.8.0.time_stack\n",
      "output_blocks.8.0.time_stack.in_layers\n",
      "output_blocks.8.0.time_stack.in_layers.0\n",
      "output_blocks.8.0.time_stack.in_layers.1\n",
      "output_blocks.8.0.time_stack.in_layers.2\n",
      "output_blocks.8.0.time_stack.h_upd\n",
      "output_blocks.8.0.time_stack.emb_layers\n",
      "output_blocks.8.0.time_stack.emb_layers.0\n",
      "output_blocks.8.0.time_stack.emb_layers.1\n",
      "output_blocks.8.0.time_stack.out_layers\n",
      "output_blocks.8.0.time_stack.out_layers.0\n",
      "output_blocks.8.0.time_stack.out_layers.1\n",
      "output_blocks.8.0.time_stack.out_layers.2\n",
      "output_blocks.8.0.time_stack.out_layers.3\n",
      "output_blocks.8.0.time_stack.skip_connection\n",
      "output_blocks.8.0.time_mixer\n",
      "output_blocks.8.1\n",
      "output_blocks.8.1.norm\n",
      "output_blocks.8.1.proj_in\n",
      "output_blocks.8.1.transformer_blocks\n",
      "output_blocks.8.1.transformer_blocks.0\n",
      "output_blocks.8.1.transformer_blocks.0.attn1\n",
      "output_blocks.8.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.8.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.8.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.8.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.8.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.8.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.8.1.transformer_blocks.0.ff\n",
      "output_blocks.8.1.transformer_blocks.0.ff.net\n",
      "output_blocks.8.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.8.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.8.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.8.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.8.1.transformer_blocks.0.attn2\n",
      "output_blocks.8.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.8.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.8.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.8.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.8.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.8.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.8.1.transformer_blocks.0.norm1\n",
      "output_blocks.8.1.transformer_blocks.0.norm2\n",
      "output_blocks.8.1.transformer_blocks.0.norm3\n",
      "output_blocks.8.1.proj_out\n",
      "output_blocks.8.1.time_stack\n",
      "output_blocks.8.1.time_stack.0\n",
      "output_blocks.8.1.time_stack.0.norm_in\n",
      "output_blocks.8.1.time_stack.0.ff_in\n",
      "output_blocks.8.1.time_stack.0.ff_in.net\n",
      "output_blocks.8.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.8.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.8.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.8.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.8.1.time_stack.0.attn1\n",
      "output_blocks.8.1.time_stack.0.attn1.to_q\n",
      "output_blocks.8.1.time_stack.0.attn1.to_k\n",
      "output_blocks.8.1.time_stack.0.attn1.to_v\n",
      "output_blocks.8.1.time_stack.0.attn1.to_out\n",
      "output_blocks.8.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.8.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.8.1.time_stack.0.ff\n",
      "output_blocks.8.1.time_stack.0.ff.net\n",
      "output_blocks.8.1.time_stack.0.ff.net.0\n",
      "output_blocks.8.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.8.1.time_stack.0.ff.net.1\n",
      "output_blocks.8.1.time_stack.0.ff.net.2\n",
      "output_blocks.8.1.time_stack.0.norm2\n",
      "output_blocks.8.1.time_stack.0.attn2\n",
      "output_blocks.8.1.time_stack.0.attn2.to_q\n",
      "output_blocks.8.1.time_stack.0.attn2.to_k\n",
      "output_blocks.8.1.time_stack.0.attn2.to_v\n",
      "output_blocks.8.1.time_stack.0.attn2.to_out\n",
      "output_blocks.8.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.8.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.8.1.time_stack.0.norm1\n",
      "output_blocks.8.1.time_stack.0.norm3\n",
      "output_blocks.8.1.time_pos_embed\n",
      "output_blocks.8.1.time_pos_embed.0\n",
      "output_blocks.8.1.time_pos_embed.1\n",
      "output_blocks.8.1.time_pos_embed.2\n",
      "output_blocks.8.1.time_mixer\n",
      "output_blocks.8.2\n",
      "output_blocks.8.2.conv\n",
      "output_blocks.9\n",
      "output_blocks.9.0\n",
      "output_blocks.9.0.in_layers\n",
      "output_blocks.9.0.in_layers.0\n",
      "output_blocks.9.0.in_layers.1\n",
      "output_blocks.9.0.in_layers.2\n",
      "output_blocks.9.0.h_upd\n",
      "output_blocks.9.0.emb_layers\n",
      "output_blocks.9.0.emb_layers.0\n",
      "output_blocks.9.0.emb_layers.1\n",
      "output_blocks.9.0.out_layers\n",
      "output_blocks.9.0.out_layers.0\n",
      "output_blocks.9.0.out_layers.1\n",
      "output_blocks.9.0.out_layers.2\n",
      "output_blocks.9.0.out_layers.3\n",
      "output_blocks.9.0.skip_connection\n",
      "output_blocks.9.0.time_stack\n",
      "output_blocks.9.0.time_stack.in_layers\n",
      "output_blocks.9.0.time_stack.in_layers.0\n",
      "output_blocks.9.0.time_stack.in_layers.1\n",
      "output_blocks.9.0.time_stack.in_layers.2\n",
      "output_blocks.9.0.time_stack.h_upd\n",
      "output_blocks.9.0.time_stack.emb_layers\n",
      "output_blocks.9.0.time_stack.emb_layers.0\n",
      "output_blocks.9.0.time_stack.emb_layers.1\n",
      "output_blocks.9.0.time_stack.out_layers\n",
      "output_blocks.9.0.time_stack.out_layers.0\n",
      "output_blocks.9.0.time_stack.out_layers.1\n",
      "output_blocks.9.0.time_stack.out_layers.2\n",
      "output_blocks.9.0.time_stack.out_layers.3\n",
      "output_blocks.9.0.time_stack.skip_connection\n",
      "output_blocks.9.0.time_mixer\n",
      "output_blocks.9.1\n",
      "output_blocks.9.1.norm\n",
      "output_blocks.9.1.proj_in\n",
      "output_blocks.9.1.transformer_blocks\n",
      "output_blocks.9.1.transformer_blocks.0\n",
      "output_blocks.9.1.transformer_blocks.0.attn1\n",
      "output_blocks.9.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.9.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.9.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.9.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.9.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.9.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.9.1.transformer_blocks.0.ff\n",
      "output_blocks.9.1.transformer_blocks.0.ff.net\n",
      "output_blocks.9.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.9.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.9.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.9.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.9.1.transformer_blocks.0.attn2\n",
      "output_blocks.9.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.9.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.9.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.9.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.9.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.9.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.9.1.transformer_blocks.0.norm1\n",
      "output_blocks.9.1.transformer_blocks.0.norm2\n",
      "output_blocks.9.1.transformer_blocks.0.norm3\n",
      "output_blocks.9.1.proj_out\n",
      "output_blocks.9.1.time_stack\n",
      "output_blocks.9.1.time_stack.0\n",
      "output_blocks.9.1.time_stack.0.norm_in\n",
      "output_blocks.9.1.time_stack.0.ff_in\n",
      "output_blocks.9.1.time_stack.0.ff_in.net\n",
      "output_blocks.9.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.9.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.9.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.9.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.9.1.time_stack.0.attn1\n",
      "output_blocks.9.1.time_stack.0.attn1.to_q\n",
      "output_blocks.9.1.time_stack.0.attn1.to_k\n",
      "output_blocks.9.1.time_stack.0.attn1.to_v\n",
      "output_blocks.9.1.time_stack.0.attn1.to_out\n",
      "output_blocks.9.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.9.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.9.1.time_stack.0.ff\n",
      "output_blocks.9.1.time_stack.0.ff.net\n",
      "output_blocks.9.1.time_stack.0.ff.net.0\n",
      "output_blocks.9.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.9.1.time_stack.0.ff.net.1\n",
      "output_blocks.9.1.time_stack.0.ff.net.2\n",
      "output_blocks.9.1.time_stack.0.norm2\n",
      "output_blocks.9.1.time_stack.0.attn2\n",
      "output_blocks.9.1.time_stack.0.attn2.to_q\n",
      "output_blocks.9.1.time_stack.0.attn2.to_k\n",
      "output_blocks.9.1.time_stack.0.attn2.to_v\n",
      "output_blocks.9.1.time_stack.0.attn2.to_out\n",
      "output_blocks.9.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.9.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.9.1.time_stack.0.norm1\n",
      "output_blocks.9.1.time_stack.0.norm3\n",
      "output_blocks.9.1.time_pos_embed\n",
      "output_blocks.9.1.time_pos_embed.0\n",
      "output_blocks.9.1.time_pos_embed.1\n",
      "output_blocks.9.1.time_pos_embed.2\n",
      "output_blocks.9.1.time_mixer\n",
      "output_blocks.10\n",
      "output_blocks.10.0\n",
      "output_blocks.10.0.in_layers\n",
      "output_blocks.10.0.in_layers.0\n",
      "output_blocks.10.0.in_layers.1\n",
      "output_blocks.10.0.in_layers.2\n",
      "output_blocks.10.0.h_upd\n",
      "output_blocks.10.0.emb_layers\n",
      "output_blocks.10.0.emb_layers.0\n",
      "output_blocks.10.0.emb_layers.1\n",
      "output_blocks.10.0.out_layers\n",
      "output_blocks.10.0.out_layers.0\n",
      "output_blocks.10.0.out_layers.1\n",
      "output_blocks.10.0.out_layers.2\n",
      "output_blocks.10.0.out_layers.3\n",
      "output_blocks.10.0.skip_connection\n",
      "output_blocks.10.0.time_stack\n",
      "output_blocks.10.0.time_stack.in_layers\n",
      "output_blocks.10.0.time_stack.in_layers.0\n",
      "output_blocks.10.0.time_stack.in_layers.1\n",
      "output_blocks.10.0.time_stack.in_layers.2\n",
      "output_blocks.10.0.time_stack.h_upd\n",
      "output_blocks.10.0.time_stack.emb_layers\n",
      "output_blocks.10.0.time_stack.emb_layers.0\n",
      "output_blocks.10.0.time_stack.emb_layers.1\n",
      "output_blocks.10.0.time_stack.out_layers\n",
      "output_blocks.10.0.time_stack.out_layers.0\n",
      "output_blocks.10.0.time_stack.out_layers.1\n",
      "output_blocks.10.0.time_stack.out_layers.2\n",
      "output_blocks.10.0.time_stack.out_layers.3\n",
      "output_blocks.10.0.time_stack.skip_connection\n",
      "output_blocks.10.0.time_mixer\n",
      "output_blocks.10.1\n",
      "output_blocks.10.1.norm\n",
      "output_blocks.10.1.proj_in\n",
      "output_blocks.10.1.transformer_blocks\n",
      "output_blocks.10.1.transformer_blocks.0\n",
      "output_blocks.10.1.transformer_blocks.0.attn1\n",
      "output_blocks.10.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.10.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.10.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.10.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.10.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.10.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.10.1.transformer_blocks.0.ff\n",
      "output_blocks.10.1.transformer_blocks.0.ff.net\n",
      "output_blocks.10.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.10.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.10.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.10.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.10.1.transformer_blocks.0.attn2\n",
      "output_blocks.10.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.10.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.10.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.10.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.10.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.10.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.10.1.transformer_blocks.0.norm1\n",
      "output_blocks.10.1.transformer_blocks.0.norm2\n",
      "output_blocks.10.1.transformer_blocks.0.norm3\n",
      "output_blocks.10.1.proj_out\n",
      "output_blocks.10.1.time_stack\n",
      "output_blocks.10.1.time_stack.0\n",
      "output_blocks.10.1.time_stack.0.norm_in\n",
      "output_blocks.10.1.time_stack.0.ff_in\n",
      "output_blocks.10.1.time_stack.0.ff_in.net\n",
      "output_blocks.10.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.10.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.10.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.10.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.10.1.time_stack.0.attn1\n",
      "output_blocks.10.1.time_stack.0.attn1.to_q\n",
      "output_blocks.10.1.time_stack.0.attn1.to_k\n",
      "output_blocks.10.1.time_stack.0.attn1.to_v\n",
      "output_blocks.10.1.time_stack.0.attn1.to_out\n",
      "output_blocks.10.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.10.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.10.1.time_stack.0.ff\n",
      "output_blocks.10.1.time_stack.0.ff.net\n",
      "output_blocks.10.1.time_stack.0.ff.net.0\n",
      "output_blocks.10.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.10.1.time_stack.0.ff.net.1\n",
      "output_blocks.10.1.time_stack.0.ff.net.2\n",
      "output_blocks.10.1.time_stack.0.norm2\n",
      "output_blocks.10.1.time_stack.0.attn2\n",
      "output_blocks.10.1.time_stack.0.attn2.to_q\n",
      "output_blocks.10.1.time_stack.0.attn2.to_k\n",
      "output_blocks.10.1.time_stack.0.attn2.to_v\n",
      "output_blocks.10.1.time_stack.0.attn2.to_out\n",
      "output_blocks.10.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.10.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.10.1.time_stack.0.norm1\n",
      "output_blocks.10.1.time_stack.0.norm3\n",
      "output_blocks.10.1.time_pos_embed\n",
      "output_blocks.10.1.time_pos_embed.0\n",
      "output_blocks.10.1.time_pos_embed.1\n",
      "output_blocks.10.1.time_pos_embed.2\n",
      "output_blocks.10.1.time_mixer\n",
      "output_blocks.11\n",
      "output_blocks.11.0\n",
      "output_blocks.11.0.in_layers\n",
      "output_blocks.11.0.in_layers.0\n",
      "output_blocks.11.0.in_layers.1\n",
      "output_blocks.11.0.in_layers.2\n",
      "output_blocks.11.0.h_upd\n",
      "output_blocks.11.0.emb_layers\n",
      "output_blocks.11.0.emb_layers.0\n",
      "output_blocks.11.0.emb_layers.1\n",
      "output_blocks.11.0.out_layers\n",
      "output_blocks.11.0.out_layers.0\n",
      "output_blocks.11.0.out_layers.1\n",
      "output_blocks.11.0.out_layers.2\n",
      "output_blocks.11.0.out_layers.3\n",
      "output_blocks.11.0.skip_connection\n",
      "output_blocks.11.0.time_stack\n",
      "output_blocks.11.0.time_stack.in_layers\n",
      "output_blocks.11.0.time_stack.in_layers.0\n",
      "output_blocks.11.0.time_stack.in_layers.1\n",
      "output_blocks.11.0.time_stack.in_layers.2\n",
      "output_blocks.11.0.time_stack.h_upd\n",
      "output_blocks.11.0.time_stack.emb_layers\n",
      "output_blocks.11.0.time_stack.emb_layers.0\n",
      "output_blocks.11.0.time_stack.emb_layers.1\n",
      "output_blocks.11.0.time_stack.out_layers\n",
      "output_blocks.11.0.time_stack.out_layers.0\n",
      "output_blocks.11.0.time_stack.out_layers.1\n",
      "output_blocks.11.0.time_stack.out_layers.2\n",
      "output_blocks.11.0.time_stack.out_layers.3\n",
      "output_blocks.11.0.time_stack.skip_connection\n",
      "output_blocks.11.0.time_mixer\n",
      "output_blocks.11.1\n",
      "output_blocks.11.1.norm\n",
      "output_blocks.11.1.proj_in\n",
      "output_blocks.11.1.transformer_blocks\n",
      "output_blocks.11.1.transformer_blocks.0\n",
      "output_blocks.11.1.transformer_blocks.0.attn1\n",
      "output_blocks.11.1.transformer_blocks.0.attn1.to_q\n",
      "output_blocks.11.1.transformer_blocks.0.attn1.to_k\n",
      "output_blocks.11.1.transformer_blocks.0.attn1.to_v\n",
      "output_blocks.11.1.transformer_blocks.0.attn1.to_out\n",
      "output_blocks.11.1.transformer_blocks.0.attn1.to_out.0\n",
      "output_blocks.11.1.transformer_blocks.0.attn1.to_out.1\n",
      "output_blocks.11.1.transformer_blocks.0.ff\n",
      "output_blocks.11.1.transformer_blocks.0.ff.net\n",
      "output_blocks.11.1.transformer_blocks.0.ff.net.0\n",
      "output_blocks.11.1.transformer_blocks.0.ff.net.0.proj\n",
      "output_blocks.11.1.transformer_blocks.0.ff.net.1\n",
      "output_blocks.11.1.transformer_blocks.0.ff.net.2\n",
      "output_blocks.11.1.transformer_blocks.0.attn2\n",
      "output_blocks.11.1.transformer_blocks.0.attn2.to_q\n",
      "output_blocks.11.1.transformer_blocks.0.attn2.to_k\n",
      "output_blocks.11.1.transformer_blocks.0.attn2.to_v\n",
      "output_blocks.11.1.transformer_blocks.0.attn2.to_out\n",
      "output_blocks.11.1.transformer_blocks.0.attn2.to_out.0\n",
      "output_blocks.11.1.transformer_blocks.0.attn2.to_out.1\n",
      "output_blocks.11.1.transformer_blocks.0.norm1\n",
      "output_blocks.11.1.transformer_blocks.0.norm2\n",
      "output_blocks.11.1.transformer_blocks.0.norm3\n",
      "output_blocks.11.1.proj_out\n",
      "output_blocks.11.1.time_stack\n",
      "output_blocks.11.1.time_stack.0\n",
      "output_blocks.11.1.time_stack.0.norm_in\n",
      "output_blocks.11.1.time_stack.0.ff_in\n",
      "output_blocks.11.1.time_stack.0.ff_in.net\n",
      "output_blocks.11.1.time_stack.0.ff_in.net.0\n",
      "output_blocks.11.1.time_stack.0.ff_in.net.0.proj\n",
      "output_blocks.11.1.time_stack.0.ff_in.net.1\n",
      "output_blocks.11.1.time_stack.0.ff_in.net.2\n",
      "output_blocks.11.1.time_stack.0.attn1\n",
      "output_blocks.11.1.time_stack.0.attn1.to_q\n",
      "output_blocks.11.1.time_stack.0.attn1.to_k\n",
      "output_blocks.11.1.time_stack.0.attn1.to_v\n",
      "output_blocks.11.1.time_stack.0.attn1.to_out\n",
      "output_blocks.11.1.time_stack.0.attn1.to_out.0\n",
      "output_blocks.11.1.time_stack.0.attn1.to_out.1\n",
      "output_blocks.11.1.time_stack.0.ff\n",
      "output_blocks.11.1.time_stack.0.ff.net\n",
      "output_blocks.11.1.time_stack.0.ff.net.0\n",
      "output_blocks.11.1.time_stack.0.ff.net.0.proj\n",
      "output_blocks.11.1.time_stack.0.ff.net.1\n",
      "output_blocks.11.1.time_stack.0.ff.net.2\n",
      "output_blocks.11.1.time_stack.0.norm2\n",
      "output_blocks.11.1.time_stack.0.attn2\n",
      "output_blocks.11.1.time_stack.0.attn2.to_q\n",
      "output_blocks.11.1.time_stack.0.attn2.to_k\n",
      "output_blocks.11.1.time_stack.0.attn2.to_v\n",
      "output_blocks.11.1.time_stack.0.attn2.to_out\n",
      "output_blocks.11.1.time_stack.0.attn2.to_out.0\n",
      "output_blocks.11.1.time_stack.0.attn2.to_out.1\n",
      "output_blocks.11.1.time_stack.0.norm1\n",
      "output_blocks.11.1.time_stack.0.norm3\n",
      "output_blocks.11.1.time_pos_embed\n",
      "output_blocks.11.1.time_pos_embed.0\n",
      "output_blocks.11.1.time_pos_embed.1\n",
      "output_blocks.11.1.time_pos_embed.2\n",
      "output_blocks.11.1.time_mixer\n",
      "out\n",
      "out.0\n",
      "out.1\n",
      "out.2\n"
     ]
    }
   ],
   "source": [
    "for name, module in unet.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraModel, LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"output_blocks.10.1.time_stack.0.attn2.to_q\"],\n",
    ")\n",
    "lora_unet = LoraModel(unet, lora_config, \"bite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraModel(\n",
       "  (model): VideoUNet(\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (label_emb): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (input_blocks): ModuleList(\n",
       "      (0): TimestepEmbedSequential(\n",
       "        (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (3): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): Downsample(\n",
       "          (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (middle_block): TimestepEmbedSequential(\n",
       "      (0): VideoResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "        (time_stack): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (time_mixer): AlphaBlender()\n",
       "      )\n",
       "      (1): SpatialVideoTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): MemoryEfficientCrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): MemoryEfficientCrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (time_stack): ModuleList(\n",
       "          (0): VideoTransformerBlock(\n",
       "            (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff_in): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn1): MemoryEfficientCrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): MemoryEfficientCrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (time_pos_embed): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (time_mixer): AlphaBlender()\n",
       "      )\n",
       "      (2): VideoResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "        (time_stack): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (time_mixer): AlphaBlender()\n",
       "      )\n",
       "    )\n",
       "    (output_blocks): ModuleList(\n",
       "      (0-1): 2 x TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (2): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (5): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (7): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (8): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=640, out_features=2560, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (2): Upsample(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (9): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (10): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (bite): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (bite): Linear(in_features=320, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (bite): Linear(in_features=8, out_features=320, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (11): TimestepEmbedSequential(\n",
       "        (0): VideoResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (time_stack): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatialVideoTransformer(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (time_stack): ModuleList(\n",
       "            (0): VideoTransformerBlock(\n",
       "              (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (attn1): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (ff): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): MemoryEfficientCrossAttention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): Sequential(\n",
       "            (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loraunet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
